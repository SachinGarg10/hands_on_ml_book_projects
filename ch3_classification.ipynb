{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-Learn provides many helper functions to download popular datasets. MNIST is one of them. The following code fetches the MNIST dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = fetch_openml('mnist_784', version=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'categories', 'feature_names', 'target_names', 'DESCR', 'details', 'url'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets loaded by Scikit-Learn generally have a similar dictionary structure, including the following:\n",
    "* A DESCR key describing the dataset\n",
    "* A data key containing an array with one row per instance and one column per feature\n",
    "* A target key containing an array with the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = mnist['data'], mnist['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((70000, 784), (70000,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 70,000 images, and each image has 784 features. This is because each image is 28 × 28 pixels, and each feature simply represents one pixel’s intensity, from 0 (white) to 255 (black). Let’s take a peek at one digit from the dataset. All you need to do is grab an instance’s feature vector, reshape it to a 28 × 28 array, and display it using Matplotlib’s imshow() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_digit = X[0]\n",
    "some_digit_image = some_digit.reshape(28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(some_digit_image, cmap='binary')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks like a 5, and indeed that’s what the label tells us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the label is a string. Most ML algorithms expect numbers, so let’s cast y to integer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But wait! You should always create a test set and set it aside before inspecting the data closely. The MNIST dataset is actually already split into a training set (the first 60,000 images) and a test set (the last 10,000 images):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training set is already shuffled for us, which is good because this guarantees that all cross-validation folds will be similar (you don’t want one fold to be missing some digits). `Moreover, some learning algorithms are sensitive to the order of the training instances, and they perform poorly if they get many similar instances in a row.` Shuffling the dataset ensures that this won’t happen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a Binary Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s simplify the problem for now and only try to identify one digit—for example, the number 5. This “5-detector” will be an example of a binary classifier, capable of distinguishing between just two classes, 5 and not-5. Let’s create the target vectors for this classification task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_5 = (y_train == 5) # True for all 5s, and False otherwise\n",
    "y_test_5 = (y_test == 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s pick a classifier and train it. A good place to start is with a `Stochastic Gradient Descent (SGD) classifier`, using Scikit-Learn’s `SGDClassifier` class. This classifier has the advantage of being capable of handling very large datasets efficiently. `This is in part because SGD deals with training instances independently, one at a time (which also makes SGD well suited for online learning)`, as we will see later. Let’s create an SGDClassifier and train it on the whole training se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(random_state=42)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_clf = SGDClassifier(random_state=42)\n",
    "sgd_clf.fit(X_train, y_train_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TIP\n",
    "\n",
    "The `SGDClassifier` relies on randomness during training (hence the name “stochastic”). If you want reproducible results, you should set the `random_state` parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use it to detect images of Number 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_clf.predict([some_digit])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classifier guesses that this image represents a 5 (True). Looks like it guessed right in this particular case! Now, let's evaluate this model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating a classifier is often significantly trickier than evaluating a regressor, so we will spend a large part of this chapter on this topic. There are many performance measures available, so grab another coffee and get ready to learn many new concepts and acronyms!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measuring Accuracy Using Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good way to evaluate a model is to use cross-validation, just as you did in Chapter 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing CROSS-VALIDATION\n",
    "\n",
    "> Occasionally you will need more control over the cross-validation process than what Scikit-Learn provides off the shelf. In these cases, you can implement cross-validation yourself. The following code does roughly the same thing as Scikit-Learn’s `cross_val_score()` function, and it prints the same result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
    "from sklearn.base import clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mStratifiedShuffleSplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtrain_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mSource:\u001b[0m        \n",
       "\u001b[0;32mclass\u001b[0m \u001b[0mStratifiedShuffleSplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseShuffleSplit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Stratified ShuffleSplit cross-validator\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Provides train/test indices to split data in train/test sets.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    This cross-validation object is a merge of StratifiedKFold and\u001b[0m\n",
       "\u001b[0;34m    ShuffleSplit, which returns stratified randomized folds. The folds\u001b[0m\n",
       "\u001b[0;34m    are made by preserving the percentage of samples for each class.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Note: like the ShuffleSplit strategy, stratified random splits\u001b[0m\n",
       "\u001b[0;34m    do not guarantee that all folds will be different, although this is\u001b[0m\n",
       "\u001b[0;34m    still very likely for sizeable datasets.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Read more in the :ref:`User Guide <cross_validation>`.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Parameters\u001b[0m\n",
       "\u001b[0;34m    ----------\u001b[0m\n",
       "\u001b[0;34m    n_splits : int, default=10\u001b[0m\n",
       "\u001b[0;34m        Number of re-shuffling & splitting iterations.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    test_size : float or int, default=None\u001b[0m\n",
       "\u001b[0;34m        If float, should be between 0.0 and 1.0 and represent the proportion\u001b[0m\n",
       "\u001b[0;34m        of the dataset to include in the test split. If int, represents the\u001b[0m\n",
       "\u001b[0;34m        absolute number of test samples. If None, the value is set to the\u001b[0m\n",
       "\u001b[0;34m        complement of the train size. If ``train_size`` is also None, it will\u001b[0m\n",
       "\u001b[0;34m        be set to 0.1.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    train_size : float or int, default=None\u001b[0m\n",
       "\u001b[0;34m        If float, should be between 0.0 and 1.0 and represent the\u001b[0m\n",
       "\u001b[0;34m        proportion of the dataset to include in the train split. If\u001b[0m\n",
       "\u001b[0;34m        int, represents the absolute number of train samples. If None,\u001b[0m\n",
       "\u001b[0;34m        the value is automatically set to the complement of the test size.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    random_state : int or RandomState instance, default=None\u001b[0m\n",
       "\u001b[0;34m        Controls the randomness of the training and testing indices produced.\u001b[0m\n",
       "\u001b[0;34m        Pass an int for reproducible output across multiple function calls.\u001b[0m\n",
       "\u001b[0;34m        See :term:`Glossary <random_state>`.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Examples\u001b[0m\n",
       "\u001b[0;34m    --------\u001b[0m\n",
       "\u001b[0;34m    >>> import numpy as np\u001b[0m\n",
       "\u001b[0;34m    >>> from sklearn.model_selection import StratifiedShuffleSplit\u001b[0m\n",
       "\u001b[0;34m    >>> X = np.array([[1, 2], [3, 4], [1, 2], [3, 4], [1, 2], [3, 4]])\u001b[0m\n",
       "\u001b[0;34m    >>> y = np.array([0, 0, 0, 1, 1, 1])\u001b[0m\n",
       "\u001b[0;34m    >>> sss = StratifiedShuffleSplit(n_splits=5, test_size=0.5, random_state=0)\u001b[0m\n",
       "\u001b[0;34m    >>> sss.get_n_splits(X, y)\u001b[0m\n",
       "\u001b[0;34m    5\u001b[0m\n",
       "\u001b[0;34m    >>> print(sss)\u001b[0m\n",
       "\u001b[0;34m    StratifiedShuffleSplit(n_splits=5, random_state=0, ...)\u001b[0m\n",
       "\u001b[0;34m    >>> for train_index, test_index in sss.split(X, y):\u001b[0m\n",
       "\u001b[0;34m    ...     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\u001b[0m\n",
       "\u001b[0;34m    ...     X_train, X_test = X[train_index], X[test_index]\u001b[0m\n",
       "\u001b[0;34m    ...     y_train, y_test = y[train_index], y[test_index]\u001b[0m\n",
       "\u001b[0;34m    TRAIN: [5 2 3] TEST: [4 1 0]\u001b[0m\n",
       "\u001b[0;34m    TRAIN: [5 1 4] TEST: [0 2 3]\u001b[0m\n",
       "\u001b[0;34m    TRAIN: [5 0 2] TEST: [4 3 1]\u001b[0m\n",
       "\u001b[0;34m    TRAIN: [4 1 0] TEST: [2 3 5]\u001b[0m\n",
       "\u001b[0;34m    TRAIN: [0 5 1] TEST: [3 4 2]\u001b[0m\n",
       "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m@\u001b[0m\u001b[0m_deprecate_positional_args\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                 \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mtrain_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_test_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_iter_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mn_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_shuffle_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mdefault_test_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_test_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# for multi-label y, map each distinct row to a string repr\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# using join because str(row) uses an ellipsis if len(row) > 1000\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'str'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mn_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mclass_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbincount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_counts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The least populated class in y has only 1\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                             \u001b[0;34m\" member, which is too few. The minimum\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                             \u001b[0;34m\" number of groups for any class cannot\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                             \u001b[0;34m\" be less than 2.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mn_train\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The train_size = %d should be greater or '\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                             \u001b[0;34m'equal to the number of classes = %d'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                             \u001b[0;34m(\u001b[0m\u001b[0mn_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mn_test\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The test_size = %d should be greater or '\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                             \u001b[0;34m'equal to the number of classes = %d'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                             \u001b[0;34m(\u001b[0m\u001b[0mn_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# Find the sorted list of instances for each class:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# (np.unique above performs a sort, so code is O(n logn) already)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mclass_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mergesort'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                 \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_counts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mrng\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# if there are ties in the class-counts, we want\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# to make sure to break them anew in each iteration\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mn_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_approximate_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_counts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrng\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mclass_counts_remaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclass_counts\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn_i\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mt_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_approximate_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_counts_remaining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrng\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mpermutation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrng\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_counts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mperm_indices_class_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclass_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                                             \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'clip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperm_indices_class_i\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_i\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperm_indices_class_i\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_i\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_i\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mt_i\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrng\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrng\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32myield\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"Generate indices to split data into training and test set.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Parameters\u001b[0m\n",
       "\u001b[0;34m        ----------\u001b[0m\n",
       "\u001b[0;34m        X : array-like of shape (n_samples, n_features)\u001b[0m\n",
       "\u001b[0;34m            Training data, where n_samples is the number of samples\u001b[0m\n",
       "\u001b[0;34m            and n_features is the number of features.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m            Note that providing ``y`` is sufficient to generate the splits and\u001b[0m\n",
       "\u001b[0;34m            hence ``np.zeros(n_samples)`` may be used as a placeholder for\u001b[0m\n",
       "\u001b[0;34m            ``X`` instead of actual training data.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        y : array-like of shape (n_samples,) or (n_samples, n_labels)\u001b[0m\n",
       "\u001b[0;34m            The target variable for supervised learning problems.\u001b[0m\n",
       "\u001b[0;34m            Stratification is done based on the y labels.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        groups : object\u001b[0m\n",
       "\u001b[0;34m            Always ignored, exists for compatibility.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Yields\u001b[0m\n",
       "\u001b[0;34m        ------\u001b[0m\n",
       "\u001b[0;34m        train : ndarray\u001b[0m\n",
       "\u001b[0;34m            The training set indices for that split.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        test : ndarray\u001b[0m\n",
       "\u001b[0;34m            The testing set indices for that split.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Notes\u001b[0m\n",
       "\u001b[0;34m        -----\u001b[0m\n",
       "\u001b[0;34m        Randomized CV splitters may return different results for each call of\u001b[0m\n",
       "\u001b[0;34m        split. You can make the results identical by setting `random_state`\u001b[0m\n",
       "\u001b[0;34m        to an integer.\u001b[0m\n",
       "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m           ~/Documents/venv/tlfMaths3.6/lib/python3.6/site-packages/sklearn/model_selection/_split.py\n",
       "\u001b[0;31mType:\u001b[0m           ABCMeta\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "StratifiedShuffleSplit??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mSource:\u001b[0m        \n",
       "\u001b[0;32mclass\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_BaseKFold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Stratified K-Folds cross-validator\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Provides train/test indices to split data in train/test sets.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    This cross-validation object is a variation of KFold that returns\u001b[0m\n",
       "\u001b[0;34m    stratified folds. The folds are made by preserving the percentage of\u001b[0m\n",
       "\u001b[0;34m    samples for each class.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Read more in the :ref:`User Guide <cross_validation>`.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Parameters\u001b[0m\n",
       "\u001b[0;34m    ----------\u001b[0m\n",
       "\u001b[0;34m    n_splits : int, default=5\u001b[0m\n",
       "\u001b[0;34m        Number of folds. Must be at least 2.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        .. versionchanged:: 0.22\u001b[0m\n",
       "\u001b[0;34m            ``n_splits`` default value changed from 3 to 5.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    shuffle : bool, default=False\u001b[0m\n",
       "\u001b[0;34m        Whether to shuffle each class's samples before splitting into batches.\u001b[0m\n",
       "\u001b[0;34m        Note that the samples within each split will not be shuffled.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    random_state : int or RandomState instance, default=None\u001b[0m\n",
       "\u001b[0;34m        When `shuffle` is True, `random_state` affects the ordering of the\u001b[0m\n",
       "\u001b[0;34m        indices, which controls the randomness of each fold for each class.\u001b[0m\n",
       "\u001b[0;34m        Otherwise, leave `random_state` as `None`.\u001b[0m\n",
       "\u001b[0;34m        Pass an int for reproducible output across multiple function calls.\u001b[0m\n",
       "\u001b[0;34m        See :term:`Glossary <random_state>`.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Examples\u001b[0m\n",
       "\u001b[0;34m    --------\u001b[0m\n",
       "\u001b[0;34m    >>> import numpy as np\u001b[0m\n",
       "\u001b[0;34m    >>> from sklearn.model_selection import StratifiedKFold\u001b[0m\n",
       "\u001b[0;34m    >>> X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\u001b[0m\n",
       "\u001b[0;34m    >>> y = np.array([0, 0, 1, 1])\u001b[0m\n",
       "\u001b[0;34m    >>> skf = StratifiedKFold(n_splits=2)\u001b[0m\n",
       "\u001b[0;34m    >>> skf.get_n_splits(X, y)\u001b[0m\n",
       "\u001b[0;34m    2\u001b[0m\n",
       "\u001b[0;34m    >>> print(skf)\u001b[0m\n",
       "\u001b[0;34m    StratifiedKFold(n_splits=2, random_state=None, shuffle=False)\u001b[0m\n",
       "\u001b[0;34m    >>> for train_index, test_index in skf.split(X, y):\u001b[0m\n",
       "\u001b[0;34m    ...     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\u001b[0m\n",
       "\u001b[0;34m    ...     X_train, X_test = X[train_index], X[test_index]\u001b[0m\n",
       "\u001b[0;34m    ...     y_train, y_test = y[train_index], y[test_index]\u001b[0m\n",
       "\u001b[0;34m    TRAIN: [1 3] TEST: [0 2]\u001b[0m\n",
       "\u001b[0;34m    TRAIN: [0 2] TEST: [1 3]\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Notes\u001b[0m\n",
       "\u001b[0;34m    -----\u001b[0m\n",
       "\u001b[0;34m    The implementation is designed to:\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    * Generate test sets such that all contain the same distribution of\u001b[0m\n",
       "\u001b[0;34m      classes, or as close as possible.\u001b[0m\n",
       "\u001b[0;34m    * Be invariant to class label: relabelling ``y = [\"Happy\", \"Sad\"]`` to\u001b[0m\n",
       "\u001b[0;34m      ``y = [1, 0]`` should not change the indices generated.\u001b[0m\n",
       "\u001b[0;34m    * Preserve order dependencies in the dataset ordering, when\u001b[0m\n",
       "\u001b[0;34m      ``shuffle=False``: all samples from class k in some test set were\u001b[0m\n",
       "\u001b[0;34m      contiguous in y, or separated in y by samples from classes other than k.\u001b[0m\n",
       "\u001b[0;34m    * Generate test sets where the smallest and largest differ by at most one\u001b[0m\n",
       "\u001b[0;34m      sample.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    .. versionchanged:: 0.22\u001b[0m\n",
       "\u001b[0;34m        The previous implementation did not follow the last constraint.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    See also\u001b[0m\n",
       "\u001b[0;34m    --------\u001b[0m\n",
       "\u001b[0;34m    RepeatedStratifiedKFold: Repeats Stratified K-Fold n times.\u001b[0m\n",
       "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m@\u001b[0m\u001b[0m_deprecate_positional_args\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                         \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_make_test_folds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mrng\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mtype_of_target_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mallowed_target_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'binary'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'multiclass'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mtype_of_target_y\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mallowed_target_types\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34m'Supported target types are: {}. Got {!r} instead.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0mallowed_target_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_of_target_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_inv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# y_inv encodes y according to lexicographic order. We invert y_idx to\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# map the classes so that they are encoded by order of appearance:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# 0 represents the first label appearing in y, 1 the second, etc.\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_perm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0my_encoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclass_perm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_inv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mn_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0my_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbincount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_encoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mmin_groups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_counts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_splits\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0my_counts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"n_splits=%d cannot be greater than the\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                             \u001b[0;34m\" number of members in each class.\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                             \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_splits\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmin_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The least populated class in y has only %d\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                           \u001b[0;34m\" members, which is less than n_splits=%d.\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                           \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmin_groups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUserWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# Determine the optimal number of samples from each class in each fold,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# using round robin over the sorted y. (This can be done direct from\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# counts, but that code is unreadable.)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0my_order\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_encoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mallocation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbincount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_order\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminlength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# To maintain the data order dependencies as best as possible within\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# the stratification constraint, we assign samples from each class in\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# blocks (and then mess that up when shuffle=True).\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mtest_folds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# since the kth column of allocation stores the number of samples\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# of class k in each test set, this generates blocks of fold\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# indices corresponding to the allocation for class k.\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mfolds_for_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mallocation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mrng\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolds_for_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mtest_folds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_encoded\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfolds_for_class\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mtest_folds\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_iter_test_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mtest_folds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_test_folds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32myield\u001b[0m \u001b[0mtest_folds\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"Generate indices to split data into training and test set.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Parameters\u001b[0m\n",
       "\u001b[0;34m        ----------\u001b[0m\n",
       "\u001b[0;34m        X : array-like of shape (n_samples, n_features)\u001b[0m\n",
       "\u001b[0;34m            Training data, where n_samples is the number of samples\u001b[0m\n",
       "\u001b[0;34m            and n_features is the number of features.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m            Note that providing ``y`` is sufficient to generate the splits and\u001b[0m\n",
       "\u001b[0;34m            hence ``np.zeros(n_samples)`` may be used as a placeholder for\u001b[0m\n",
       "\u001b[0;34m            ``X`` instead of actual training data.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        y : array-like of shape (n_samples,)\u001b[0m\n",
       "\u001b[0;34m            The target variable for supervised learning problems.\u001b[0m\n",
       "\u001b[0;34m            Stratification is done based on the y labels.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        groups : object\u001b[0m\n",
       "\u001b[0;34m            Always ignored, exists for compatibility.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Yields\u001b[0m\n",
       "\u001b[0;34m        ------\u001b[0m\n",
       "\u001b[0;34m        train : ndarray\u001b[0m\n",
       "\u001b[0;34m            The training set indices for that split.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        test : ndarray\u001b[0m\n",
       "\u001b[0;34m            The testing set indices for that split.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Notes\u001b[0m\n",
       "\u001b[0;34m        -----\u001b[0m\n",
       "\u001b[0;34m        Randomized CV splitters may return different results for each call of\u001b[0m\n",
       "\u001b[0;34m        split. You can make the results identical by setting `random_state`\u001b[0m\n",
       "\u001b[0;34m        to an integer.\u001b[0m\n",
       "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m           ~/Documents/venv/tlfMaths3.6/lib/python3.6/site-packages/sklearn/model_selection/_split.py\n",
       "\u001b[0;31mType:\u001b[0m           ABCMeta\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "StratifiedKFold??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "\u001b[0;34m@\u001b[0m\u001b[0m_deprecate_positional_args\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;32mdef\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Constructs a new estimator with the same parameters.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Clone does a deep copy of the model in an estimator\u001b[0m\n",
       "\u001b[0;34m    without actually copying attached data. It yields a new estimator\u001b[0m\n",
       "\u001b[0;34m    with the same parameters that has not been fit on any data.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Parameters\u001b[0m\n",
       "\u001b[0;34m    ----------\u001b[0m\n",
       "\u001b[0;34m    estimator : {list, tuple, set} of estimator objects or estimator object\u001b[0m\n",
       "\u001b[0;34m        The estimator or group of estimators to be cloned.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    safe : bool, default=True\u001b[0m\n",
       "\u001b[0;34m        If safe is false, clone will fall back to a deep copy on objects\u001b[0m\n",
       "\u001b[0;34m        that are not estimators.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mestimator_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;31m# XXX: not handling dictionaries\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mestimator_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrozenset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mestimator_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msafe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'get_params'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot clone object. \"\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                \u001b[0;34m\"You should provide an instance of \"\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                \u001b[0;34m\"scikit-learn estimator instead of a class.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot clone object '%s' (type %s): \"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                \u001b[0;34m\"it does not seem to be a scikit-learn \"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                \u001b[0;34m\"estimator as it does not implement a \"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                \u001b[0;34m\"'get_params' method.\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnew_object_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnew_object_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mnew_object_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnew_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mnew_object_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mparams_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;31m# quick sanity check of the parameters of the clone\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnew_object_params\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mparam1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_object_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mparam2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mparam1\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparam2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot clone object %s, as the constructor '\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                               \u001b[0;34m'either does not set or modifies parameter %s'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                               \u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mnew_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      ~/Documents/venv/tlfMaths3.6/lib/python3.6/site-packages/sklearn/base.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clone??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/owl/Documents/venv/tlfMaths3.6/lib/python3.6/site-packages/sklearn/model_selection/_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95035\n",
      "0.96035\n",
      "0.9604\n"
     ]
    }
   ],
   "source": [
    "skfolds = StratifiedKFold(n_splits=3, random_state=42)\n",
    "\n",
    "for train_index, test_index in skfolds.split(X_train, y_train_5):\n",
    "    clone_clf = clone(sgd_clf)\n",
    "    X_train_folds = X_train[train_index]\n",
    "    y_train_folds = y_train_5[train_index]\n",
    "    X_test_fold = X_train[test_index]\n",
    "    y_test_fold = y_train_5[test_index]\n",
    "    \n",
    "    clone_clf.fit(X_train_folds, y_train_folds)\n",
    "    y_pred = clone_clf.predict(X_test_fold)\n",
    "    n_correct = sum(y_pred == y_test_fold)\n",
    "    print(n_correct/len(y_test_fold))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The StratifiedKFold class performs stratified sampling (as explained in Chapter 2) to produce folds that contain a representative ratio of each class. At each iteration the code creates a clone of the classifier, trains that clone on the training folds, and makes predictions on the test fold. Then it counts the number of correct predictions and outputs the ratio of correct predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s use the `cross_val_score()` function to evaluate our `SGDClassifier` model, using K-fold cross-validation with three folds. Remember that K-fold cross-validation means splitting the training set into K folds (in this case, three), then making predictions and evaluating them on each fold using a model trained on the remaining folds (see Chapter 2):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.95035, 0.96035, 0.9604 ])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(sgd_clf, X_train, y_train_5, cv=3, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! Above 95% accuracy (ratio of correct predictions) on all cross-validation folds? This looks amazing, doesn’t it? Well, before you get too excited, let’s look at a `very dumb classifier` that just classifies every single image in the “not-5” class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m \u001b[0mBaseEstimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mSource:\u001b[0m        \n",
       "\u001b[0;32mclass\u001b[0m \u001b[0mBaseEstimator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Base class for all estimators in scikit-learn\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Notes\u001b[0m\n",
       "\u001b[0;34m    -----\u001b[0m\n",
       "\u001b[0;34m    All estimators should specify all the parameters that can be set\u001b[0m\n",
       "\u001b[0;34m    at the class level in their ``__init__`` as explicit keyword\u001b[0m\n",
       "\u001b[0;34m    arguments (no ``*args`` or ``**kwargs``).\u001b[0m\n",
       "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_get_param_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"Get parameter names for the estimator\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# fetch the constructor or the original constructor before\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# deprecation wrapping if any\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0minit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated_original'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0minit\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# No explicit constructor to introspect\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# introspect the constructor arguments to find the model parameters\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# to represent\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0minit_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# Consider the constructor parameters excluding 'self'\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minit_signature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                      \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'self'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVAR_KEYWORD\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVAR_POSITIONAL\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"scikit-learn estimators should always \"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                   \u001b[0;34m\"specify their parameters in the signature\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                   \u001b[0;34m\" of their __init__ (no varargs).\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                   \u001b[0;34m\" %s with constructor %s doesn't \"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                   \u001b[0;34m\" follow this convention.\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                   \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# Extract and sort argument names excluding 'self'\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"\u001b[0m\n",
       "\u001b[0;34m        Get parameters for this estimator.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Parameters\u001b[0m\n",
       "\u001b[0;34m        ----------\u001b[0m\n",
       "\u001b[0;34m        deep : bool, default=True\u001b[0m\n",
       "\u001b[0;34m            If True, will return the parameters for this estimator and\u001b[0m\n",
       "\u001b[0;34m            contained subobjects that are estimators.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Returns\u001b[0m\n",
       "\u001b[0;34m        -------\u001b[0m\n",
       "\u001b[0;34m        params : mapping of string to any\u001b[0m\n",
       "\u001b[0;34m            Parameter names mapped to their values.\u001b[0m\n",
       "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_param_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'From version 0.24, get_params will raise an '\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                              \u001b[0;34m'AttributeError if a parameter cannot be '\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                              \u001b[0;34m'retrieved as an instance attribute. Previously '\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                              \u001b[0;34m'it would return None.'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                              \u001b[0mFutureWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mdeep\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'get_params'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mdeep_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'__'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdeep_items\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"\u001b[0m\n",
       "\u001b[0;34m        Set the parameters of this estimator.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        The method works on simple estimators as well as on nested objects\u001b[0m\n",
       "\u001b[0;34m        (such as pipelines). The latter have parameters of the form\u001b[0m\n",
       "\u001b[0;34m        ``<component>__<parameter>`` so that it's possible to update each\u001b[0m\n",
       "\u001b[0;34m        component of a nested object.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Parameters\u001b[0m\n",
       "\u001b[0;34m        ----------\u001b[0m\n",
       "\u001b[0;34m        **params : dict\u001b[0m\n",
       "\u001b[0;34m            Estimator parameters.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Returns\u001b[0m\n",
       "\u001b[0;34m        -------\u001b[0m\n",
       "\u001b[0;34m        self : object\u001b[0m\n",
       "\u001b[0;34m            Estimator instance.\u001b[0m\n",
       "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# Simple optimization to gain speed (inspect is slow)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mvalid_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mnested_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# grouped by prefix\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalid_params\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Invalid parameter %s for estimator %s. '\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                 \u001b[0;34m'Check the list of available parameters '\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                 \u001b[0;34m'with `estimator.get_params().keys()`.'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                 \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mdelim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mnested_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msub_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mvalid_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_params\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnested_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mvalid_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0msub_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_CHAR_MAX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m700\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# N_CHAR_MAX is the (approximate) maximum number of non-blank\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# characters to render. We pass it as an optional parameter to ease\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# the tests.\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pprint\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_EstimatorPrettyPrinter\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mN_MAX_ELEMENTS_TO_SHOW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m  \u001b[0;31m# number of elements to show in sequences\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# use ellipsis for sequences with a lot of elements\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mpp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_EstimatorPrettyPrinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mcompact\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent_at_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mn_max_elements_to_show\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mN_MAX_ELEMENTS_TO_SHOW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mrepr_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# Use bruteforce ellipsis when there are a lot of non-blank characters\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mn_nonblank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepr_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mn_nonblank\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mN_CHAR_MAX\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mlim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mN_CHAR_MAX\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m  \u001b[0;31m# apprx number of chars to keep on both ends\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mregex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mr'^(\\s*\\S){%d}'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlim\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# The regex '^(\\s*\\S){%d}' % n\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# matches from the start of the string until the nth non-blank\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# character:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# - ^ matches the start of string\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# - (pattern){n} matches n repetitions of pattern\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# - \\s*\\S matches a non-blank char following zero or more blanks\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mleft_lim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepr_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mright_lim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepr_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0;34m'\\n'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrepr_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mleft_lim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mright_lim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;31m# The left side and right side aren't on the same line.\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;31m# To avoid weird cuts, e.g.:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;31m# categoric...ore',\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;31m# we need to start the right side with an appropriate newline\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;31m# character so that it renders properly as:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;31m# categoric...\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;31m# handle_unknown='ignore',\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;31m# so we add [^\\n]*\\n which matches until the next \\n\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mregex\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mr'[^\\n]*\\n'\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mright_lim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepr_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mellipsis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'...'\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mleft_lim\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mellipsis\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepr_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mright_lim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;31m# Only add ellipsis if it results in a shorter repr\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mrepr_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepr_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mleft_lim\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'...'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrepr_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mright_lim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mrepr_\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__getstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sklearn.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_sklearn_version\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__setstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sklearn.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mpickle_version\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_sklearn_version\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"pre-0.18\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mpickle_version\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0;34m\"Trying to unpickle estimator {0} from version {1} when \"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0;34m\"using version {2}. This might lead to breaking code or \"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0;34m\"invalid results. Use at your own risk.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0mUserWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_more_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0m_DEFAULT_TAGS\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_get_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mcollected_tags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mfor\u001b[0m \u001b[0mbase_class\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetmro\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_more_tags'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;31m# need the if because mixins might not have _more_tags\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;31m# but might do redundant work in estimators\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;31m# (i.e. calling more tags on BaseEstimator multiple times)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mmore_tags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_more_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mcollected_tags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmore_tags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mcollected_tags\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_check_n_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"Set the `n_features_in_` attribute, or check against it.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Parameters\u001b[0m\n",
       "\u001b[0;34m        ----------\u001b[0m\n",
       "\u001b[0;34m        X : {ndarray, sparse matrix} of shape (n_samples, n_features)\u001b[0m\n",
       "\u001b[0;34m            The input samples.\u001b[0m\n",
       "\u001b[0;34m        reset : bool\u001b[0m\n",
       "\u001b[0;34m            If True, the `n_features_in_` attribute is set to `X.shape[1]`.\u001b[0m\n",
       "\u001b[0;34m            Else, the attribute must already exist and the function checks\u001b[0m\n",
       "\u001b[0;34m            that it is equal to `X.shape[1]`.\u001b[0m\n",
       "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_in_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'n_features_in_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0;34m\"The reset parameter is False but there is no \"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0;34m\"n_features_in_ attribute. Is this estimator fitted?\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0;34m'X has {} features, but this {} is expecting {} features '\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0;34m'as input.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                       \u001b[0mvalidate_separately\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Parameters\u001b[0m\n",
       "\u001b[0;34m        ----------\u001b[0m\n",
       "\u001b[0;34m        X : {array-like, sparse matrix, dataframe} of shape \\\u001b[0m\n",
       "\u001b[0;34m                (n_samples, n_features)\u001b[0m\n",
       "\u001b[0;34m            The input samples.\u001b[0m\n",
       "\u001b[0;34m        y : array-like of shape (n_samples,), default=None\u001b[0m\n",
       "\u001b[0;34m            The targets. If None, `check_array` is called on `X` and\u001b[0m\n",
       "\u001b[0;34m            `check_X_y` is called otherwise.\u001b[0m\n",
       "\u001b[0;34m        reset : bool, default=True\u001b[0m\n",
       "\u001b[0;34m            Whether to reset the `n_features_in_` attribute.\u001b[0m\n",
       "\u001b[0;34m            If False, the input will be checked for consistency with data\u001b[0m\n",
       "\u001b[0;34m            provided when reset was last True.\u001b[0m\n",
       "\u001b[0;34m        validate_separately : False or tuple of dicts, default=False\u001b[0m\n",
       "\u001b[0;34m            Only used if y is not None.\u001b[0m\n",
       "\u001b[0;34m            If False, call validate_X_y(). Else, it must be a tuple of kwargs\u001b[0m\n",
       "\u001b[0;34m            to be used for calling check_array() on X and y respectively.\u001b[0m\n",
       "\u001b[0;34m        **check_params : kwargs\u001b[0m\n",
       "\u001b[0;34m            Parameters passed to :func:`sklearn.utils.check_array` or\u001b[0m\n",
       "\u001b[0;34m            :func:`sklearn.utils.check_X_y`. Ignored if validate_separately\u001b[0m\n",
       "\u001b[0;34m            is not False.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Returns\u001b[0m\n",
       "\u001b[0;34m        -------\u001b[0m\n",
       "\u001b[0;34m        out : {ndarray, sparse matrix} or tuple of these\u001b[0m\n",
       "\u001b[0;34m            The validated input. A tuple is returned if `y` is not None.\u001b[0m\n",
       "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'requires_y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0;34mf\"This {self.__class__.__name__} estimator \"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0;34mf\"requires y to be passed, but the target y is None.\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mvalidate_separately\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;31m# We need this because some estimators validate X and y\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;31m# separately, and in general, separately calling check_array()\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;31m# on X and y isn't equivalent to just calling check_X_y()\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;31m# :(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mcheck_X_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_y_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_separately\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_X_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ensure_2d'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_repr_html_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"HTML representation of estimator.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        This is redundant with the logic of `_repr_mimebundle_`. The latter\u001b[0m\n",
       "\u001b[0;34m        should be favorted in the long term, `_repr_html_` is only\u001b[0m\n",
       "\u001b[0;34m        implemented for consumers who do not interpret `_repr_mimbundle_`.\u001b[0m\n",
       "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"display\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'diagram'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_repr_html_ is only defined when the \"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                 \u001b[0;34m\"'display' configuration option is set to \"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                 \u001b[0;34m\"'diagram'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_repr_html_inner\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_repr_html_inner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"This function is returned by the @property `_repr_html_` to make\u001b[0m\n",
       "\u001b[0;34m        `hasattr(estimator, \"_repr_html_\") return `True` or `False` depending\u001b[0m\n",
       "\u001b[0;34m        on `get_config()[\"display\"]`.\u001b[0m\n",
       "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mestimator_html_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_repr_mimebundle_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"Mime bundle used by jupyter kernels to display estimator\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"text/plain\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"display\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'diagram'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text/html\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator_html_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m           ~/Documents/venv/tlfMaths3.6/lib/python3.6/site-packages/sklearn/base.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     DictVectorizer, FeatureHasher, PatchExtractor, FunctionTransformer, LabelEncoder, LabelBinarizer, MultiLabelBinarizer, _BaseEncoder, MinMaxScaler, StandardScaler, ...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BaseEstimator??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Never5Classifier(BaseEstimator):\n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.zeros((len(X), 1), dtype=bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you guess this model's accuracy? Let's find out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.91125, 0.90855, 0.90915])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "never_5_clf = Never5Classifier()\n",
    "cross_val_score(never_5_clf, X_train, y_train_5, cv=3, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That’s right, it has over 90% accuracy! This is simply because only about 10% of the images are 5s, so if you always guess that an image is not a 5, you will be right about 90% of the time. Beats Nostradamus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This demonstrates why `accuracy` is generally `not the preferred performance measure for classifiers`, especially when you are dealing with `skewed datasets` (i.e., when some classes are much more frequent than others)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A much better way to evaluate the performance of a classifier is to look at the confusion matrix. The general idea is to count the number of times instances of class A are classified as class B. </br> \n",
    "For example, to know the number of times the classifier confused images of 5s with 3s, you would look in the fifth row and third column of the confusion matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute the confusion matrix, you first need to have a set of predictions so that they can be compared to the actual targets. You could make predictions on the test set, but let’s keep it untouched for now (remember that you want to use the test set only at the very end of your project, once you have a classifier that you are ready to launch). Instead, you can use the `cross_val_predict()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mcross_val_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'2*n_jobs'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'predict'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "\u001b[0;34m@\u001b[0m\u001b[0m_deprecate_positional_args\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;32mdef\u001b[0m \u001b[0mcross_val_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                      \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                      \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'2*n_jobs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'predict'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Generate cross-validated estimates for each input data point\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    The data is split according to the cv parameter. Each sample belongs\u001b[0m\n",
       "\u001b[0;34m    to exactly one test set, and its prediction is computed with an\u001b[0m\n",
       "\u001b[0;34m    estimator fitted on the corresponding training set.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Passing these predictions into an evaluation metric may not be a valid\u001b[0m\n",
       "\u001b[0;34m    way to measure generalization performance. Results can differ from\u001b[0m\n",
       "\u001b[0;34m    :func:`cross_validate` and :func:`cross_val_score` unless all tests sets\u001b[0m\n",
       "\u001b[0;34m    have equal size and the metric decomposes over samples.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Read more in the :ref:`User Guide <cross_validation>`.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Parameters\u001b[0m\n",
       "\u001b[0;34m    ----------\u001b[0m\n",
       "\u001b[0;34m    estimator : estimator object implementing 'fit' and 'predict'\u001b[0m\n",
       "\u001b[0;34m        The object to use to fit the data.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    X : array-like of shape (n_samples, n_features)\u001b[0m\n",
       "\u001b[0;34m        The data to fit. Can be, for example a list, or an array at least 2d.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    y : array-like of shape (n_samples,) or (n_samples, n_outputs), \\\u001b[0m\n",
       "\u001b[0;34m            default=None\u001b[0m\n",
       "\u001b[0;34m        The target variable to try to predict in the case of\u001b[0m\n",
       "\u001b[0;34m        supervised learning.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    groups : array-like of shape (n_samples,), default=None\u001b[0m\n",
       "\u001b[0;34m        Group labels for the samples used while splitting the dataset into\u001b[0m\n",
       "\u001b[0;34m        train/test set. Only used in conjunction with a \"Group\" :term:`cv`\u001b[0m\n",
       "\u001b[0;34m        instance (e.g., :class:`GroupKFold`).\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    cv : int, cross-validation generator or an iterable, default=None\u001b[0m\n",
       "\u001b[0;34m        Determines the cross-validation splitting strategy.\u001b[0m\n",
       "\u001b[0;34m        Possible inputs for cv are:\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        - None, to use the default 5-fold cross validation,\u001b[0m\n",
       "\u001b[0;34m        - int, to specify the number of folds in a `(Stratified)KFold`,\u001b[0m\n",
       "\u001b[0;34m        - :term:`CV splitter`,\u001b[0m\n",
       "\u001b[0;34m        - An iterable yielding (train, test) splits as arrays of indices.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        For int/None inputs, if the estimator is a classifier and ``y`` is\u001b[0m\n",
       "\u001b[0;34m        either binary or multiclass, :class:`StratifiedKFold` is used. In all\u001b[0m\n",
       "\u001b[0;34m        other cases, :class:`KFold` is used.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Refer :ref:`User Guide <cross_validation>` for the various\u001b[0m\n",
       "\u001b[0;34m        cross-validation strategies that can be used here.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        .. versionchanged:: 0.22\u001b[0m\n",
       "\u001b[0;34m            ``cv`` default value if None changed from 3-fold to 5-fold.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    n_jobs : int, default=None\u001b[0m\n",
       "\u001b[0;34m        The number of CPUs to use to do the computation.\u001b[0m\n",
       "\u001b[0;34m        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\u001b[0m\n",
       "\u001b[0;34m        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\u001b[0m\n",
       "\u001b[0;34m        for more details.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    verbose : int, default=0\u001b[0m\n",
       "\u001b[0;34m        The verbosity level.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    fit_params : dict, defualt=None\u001b[0m\n",
       "\u001b[0;34m        Parameters to pass to the fit method of the estimator.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    pre_dispatch : int or str, default='2*n_jobs'\u001b[0m\n",
       "\u001b[0;34m        Controls the number of jobs that get dispatched during parallel\u001b[0m\n",
       "\u001b[0;34m        execution. Reducing this number can be useful to avoid an\u001b[0m\n",
       "\u001b[0;34m        explosion of memory consumption when more jobs get dispatched\u001b[0m\n",
       "\u001b[0;34m        than CPUs can process. This parameter can be:\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m            - None, in which case all the jobs are immediately\u001b[0m\n",
       "\u001b[0;34m              created and spawned. Use this for lightweight and\u001b[0m\n",
       "\u001b[0;34m              fast-running jobs, to avoid delays due to on-demand\u001b[0m\n",
       "\u001b[0;34m              spawning of the jobs\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m            - An int, giving the exact number of total jobs that are\u001b[0m\n",
       "\u001b[0;34m              spawned\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m            - A str, giving an expression as a function of n_jobs,\u001b[0m\n",
       "\u001b[0;34m              as in '2*n_jobs'\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    method : str, default='predict'\u001b[0m\n",
       "\u001b[0;34m        Invokes the passed method name of the passed estimator. For\u001b[0m\n",
       "\u001b[0;34m        method='predict_proba', the columns correspond to the classes\u001b[0m\n",
       "\u001b[0;34m        in sorted order.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Returns\u001b[0m\n",
       "\u001b[0;34m    -------\u001b[0m\n",
       "\u001b[0;34m    predictions : ndarray\u001b[0m\n",
       "\u001b[0;34m        This is the result of calling ``method``\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    See also\u001b[0m\n",
       "\u001b[0;34m    --------\u001b[0m\n",
       "\u001b[0;34m    cross_val_score : calculate score for each CV split\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    cross_validate : calculate one or more scores and timings for each CV split\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Notes\u001b[0m\n",
       "\u001b[0;34m    -----\u001b[0m\n",
       "\u001b[0;34m    In the case that one or more classes are absent in a training portion, a\u001b[0m\n",
       "\u001b[0;34m    default score needs to be assigned to all instances for that class if\u001b[0m\n",
       "\u001b[0;34m    ``method`` produces columns per class, as in {'decision_function',\u001b[0m\n",
       "\u001b[0;34m    'predict_proba', 'predict_log_proba'}.  For ``predict_proba`` this value is\u001b[0m\n",
       "\u001b[0;34m    0.  In order to ensure finite output, we approximate negative infinity by\u001b[0m\n",
       "\u001b[0;34m    the minimum finite float value for the dtype in other cases.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Examples\u001b[0m\n",
       "\u001b[0;34m    --------\u001b[0m\n",
       "\u001b[0;34m    >>> from sklearn import datasets, linear_model\u001b[0m\n",
       "\u001b[0;34m    >>> from sklearn.model_selection import cross_val_predict\u001b[0m\n",
       "\u001b[0;34m    >>> diabetes = datasets.load_diabetes()\u001b[0m\n",
       "\u001b[0;34m    >>> X = diabetes.data[:150]\u001b[0m\n",
       "\u001b[0;34m    >>> y = diabetes.target[:150]\u001b[0m\n",
       "\u001b[0;34m    >>> lasso = linear_model.Lasso()\u001b[0m\n",
       "\u001b[0;34m    >>> y_pred = cross_val_predict(lasso, X, y, cv=3)\u001b[0m\n",
       "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;31m# If classification methods produce multiple columns of output,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;31m# we need to manually encode classes to ensure consistent column ordering.\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mencode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'decision_function'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'predict_proba'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                        \u001b[0;34m'predict_log_proba'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melif\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0my_enc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mfor\u001b[0m \u001b[0mi_label\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0my_enc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi_label\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi_label\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_enc\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;31m# We clone the estimator to make sure that all the folds are\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;31m# independent, and that it is pickle-able.\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mparallel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                        \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mprediction_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_fit_and_predict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;31m# Concatenate the predictions\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpred_block_i\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpred_block_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprediction_blocks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtest_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices_i\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                   \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices_i\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprediction_blocks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_check_is_permutation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cross_val_predict only works for partitions'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0minv_test_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0minv_test_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_indices\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32melif\u001b[0m \u001b[0mencode\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# `predictions` is a list of method outputs from each fold.\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# If each of those is also a list, then treat this as a\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# multioutput-multiclass task. We need to separately concatenate\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# the method outputs for each label into an `n_labels` long list.\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mn_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mconcat_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mfor\u001b[0m \u001b[0mi_label\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mlabel_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi_label\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mconcat_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcat_pred\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minv_test_indices\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minv_test_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      ~/Documents/venv/tlfMaths3.6/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cross_val_predict??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like the `cross_val_score()` function, `cross_val_predict()` performs `K-fold cross-validation`, but instead of returning the evaluation scores, it returns the predictions made on each test fold. This means that you get a `clean prediction` for each instance in the training set (“clean” meaning that the prediction is made by a model that never saw the data during training)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you are ready to get the confusion matrix using the `confusion_matrix()` function. Just pass it the target classes (y_train_5) and the predicted classes (y_train_pred):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, (60000,))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train_pred), y_train_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[53892,   687],\n",
       "       [ 1891,  3530]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train_5, y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Each row in a confusion matrix represents an **actual class**, while each column represents a **predicted class**.\n",
    "* The first row of this matrix considers non-5 images (the negative class): 53,892 of them were correctly classified as non-5s (they are called `true negatives`), while the remaining 687 were wrongly classified as 5s (`false positives`). \n",
    "* The second row considers the images of 5s (the positive class): 1,891 were wrongly classified as non-5s (`false negatives`), while the remaining 3,530 were correctly classified as 5s (`true positives`). \n",
    "* A `perfect classifier` would have only true positives and true negatives, so its confusion matrix would have nonzero values only on its main diagonal (top left to bottom right):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[54579,     0],\n",
       "       [    0,  5421]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_perfect_predictions = y_train_5\n",
    "confusion_matrix(y_train_5, y_train_perfect_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The confusion matrix gives you a lot of information, but sometimes you may prefer a more concise metric. An interesting one to look at is the accuracy of the positive predictions; this is called the `precision of the classifier`** (Equation 3-1).\n",
    "\n",
    "**Equation 3-1. `Precision`** </br>\n",
    "$$precision = \\frac{TP}{TP + FP}$$\n",
    "\n",
    "*TP* is the number of *true positives*, and *FP* is the number of *false positives*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A trivial way to have perfect precision is to make one single positive prediction and ensure it is correct (precision = 1/1 = 100%). But this would not be very useful, since the classifier would ignore all but one positive instance. So precision is typically used along with another metric named `recall`, _also called sensitivity or the true positive rate (TPR)_: this is the ratio of positive instances that are correctly detected by the classifier** (Equation 3-2).\n",
    "\n",
    "**Equation 3-2. `Recall`** </br>\n",
    "$$recall = \\frac{TP}{TP + FN}$$\n",
    "\n",
    "FN is, of course, the number of false negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are confused about the confusion matrix, below figure may help.\n",
    "\n",
    "![Confusion Matrix Image](images/confusion_matrix.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision and Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-Learn provides several functions to compute classifier metrics, including precision and recall:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, precision_recall_curve, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mrecall_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mzero_division\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'warn'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "\u001b[0;34m@\u001b[0m\u001b[0m_deprecate_positional_args\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;32mdef\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                 \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzero_division\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"warn\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Compute the recall\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    The recall is the ratio ``tp / (tp + fn)`` where ``tp`` is the number of\u001b[0m\n",
       "\u001b[0;34m    true positives and ``fn`` the number of false negatives. The recall is\u001b[0m\n",
       "\u001b[0;34m    intuitively the ability of the classifier to find all the positive samples.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    The best value is 1 and the worst value is 0.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Read more in the :ref:`User Guide <precision_recall_f_measure_metrics>`.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Parameters\u001b[0m\n",
       "\u001b[0;34m    ----------\u001b[0m\n",
       "\u001b[0;34m    y_true : 1d array-like, or label indicator array / sparse matrix\u001b[0m\n",
       "\u001b[0;34m        Ground truth (correct) target values.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    y_pred : 1d array-like, or label indicator array / sparse matrix\u001b[0m\n",
       "\u001b[0;34m        Estimated targets as returned by a classifier.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    labels : list, optional\u001b[0m\n",
       "\u001b[0;34m        The set of labels to include when ``average != 'binary'``, and their\u001b[0m\n",
       "\u001b[0;34m        order if ``average is None``. Labels present in the data can be\u001b[0m\n",
       "\u001b[0;34m        excluded, for example to calculate a multiclass average ignoring a\u001b[0m\n",
       "\u001b[0;34m        majority negative class, while labels not present in the data will\u001b[0m\n",
       "\u001b[0;34m        result in 0 components in a macro average. For multilabel targets,\u001b[0m\n",
       "\u001b[0;34m        labels are column indices. By default, all labels in ``y_true`` and\u001b[0m\n",
       "\u001b[0;34m        ``y_pred`` are used in sorted order.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        .. versionchanged:: 0.17\u001b[0m\n",
       "\u001b[0;34m           parameter *labels* improved for multiclass problem.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    pos_label : str or int, 1 by default\u001b[0m\n",
       "\u001b[0;34m        The class to report if ``average='binary'`` and the data is binary.\u001b[0m\n",
       "\u001b[0;34m        If the data are multiclass or multilabel, this will be ignored;\u001b[0m\n",
       "\u001b[0;34m        setting ``labels=[pos_label]`` and ``average != 'binary'`` will report\u001b[0m\n",
       "\u001b[0;34m        scores for that label only.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    average : string, [None, 'binary' (default), 'micro', 'macro', 'samples', \\\u001b[0m\n",
       "\u001b[0;34m                       'weighted']\u001b[0m\n",
       "\u001b[0;34m        This parameter is required for multiclass/multilabel targets.\u001b[0m\n",
       "\u001b[0;34m        If ``None``, the scores for each class are returned. Otherwise, this\u001b[0m\n",
       "\u001b[0;34m        determines the type of averaging performed on the data:\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        ``'binary'``:\u001b[0m\n",
       "\u001b[0;34m            Only report results for the class specified by ``pos_label``.\u001b[0m\n",
       "\u001b[0;34m            This is applicable only if targets (``y_{true,pred}``) are binary.\u001b[0m\n",
       "\u001b[0;34m        ``'micro'``:\u001b[0m\n",
       "\u001b[0;34m            Calculate metrics globally by counting the total true positives,\u001b[0m\n",
       "\u001b[0;34m            false negatives and false positives.\u001b[0m\n",
       "\u001b[0;34m        ``'macro'``:\u001b[0m\n",
       "\u001b[0;34m            Calculate metrics for each label, and find their unweighted\u001b[0m\n",
       "\u001b[0;34m            mean.  This does not take label imbalance into account.\u001b[0m\n",
       "\u001b[0;34m        ``'weighted'``:\u001b[0m\n",
       "\u001b[0;34m            Calculate metrics for each label, and find their average weighted\u001b[0m\n",
       "\u001b[0;34m            by support (the number of true instances for each label). This\u001b[0m\n",
       "\u001b[0;34m            alters 'macro' to account for label imbalance; it can result in an\u001b[0m\n",
       "\u001b[0;34m            F-score that is not between precision and recall.\u001b[0m\n",
       "\u001b[0;34m        ``'samples'``:\u001b[0m\n",
       "\u001b[0;34m            Calculate metrics for each instance, and find their average (only\u001b[0m\n",
       "\u001b[0;34m            meaningful for multilabel classification where this differs from\u001b[0m\n",
       "\u001b[0;34m            :func:`accuracy_score`).\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    sample_weight : array-like of shape (n_samples,), default=None\u001b[0m\n",
       "\u001b[0;34m        Sample weights.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    zero_division : \"warn\", 0 or 1, default=\"warn\"\u001b[0m\n",
       "\u001b[0;34m        Sets the value to return when there is a zero division. If set to\u001b[0m\n",
       "\u001b[0;34m        \"warn\", this acts as 0, but warnings are also raised.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Returns\u001b[0m\n",
       "\u001b[0;34m    -------\u001b[0m\n",
       "\u001b[0;34m    recall : float (if average is not None) or array of float, shape =\\\u001b[0m\n",
       "\u001b[0;34m        [n_unique_labels]\u001b[0m\n",
       "\u001b[0;34m        Recall of the positive class in binary classification or weighted\u001b[0m\n",
       "\u001b[0;34m        average of the recall of each class for the multiclass task.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    See also\u001b[0m\n",
       "\u001b[0;34m    --------\u001b[0m\n",
       "\u001b[0;34m    precision_recall_fscore_support, balanced_accuracy_score,\u001b[0m\n",
       "\u001b[0;34m    multilabel_confusion_matrix\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Examples\u001b[0m\n",
       "\u001b[0;34m    --------\u001b[0m\n",
       "\u001b[0;34m    >>> from sklearn.metrics import recall_score\u001b[0m\n",
       "\u001b[0;34m    >>> y_true = [0, 1, 2, 0, 1, 2]\u001b[0m\n",
       "\u001b[0;34m    >>> y_pred = [0, 2, 1, 0, 0, 1]\u001b[0m\n",
       "\u001b[0;34m    >>> recall_score(y_true, y_pred, average='macro')\u001b[0m\n",
       "\u001b[0;34m    0.33...\u001b[0m\n",
       "\u001b[0;34m    >>> recall_score(y_true, y_pred, average='micro')\u001b[0m\n",
       "\u001b[0;34m    0.33...\u001b[0m\n",
       "\u001b[0;34m    >>> recall_score(y_true, y_pred, average='weighted')\u001b[0m\n",
       "\u001b[0;34m    0.33...\u001b[0m\n",
       "\u001b[0;34m    >>> recall_score(y_true, y_pred, average=None)\u001b[0m\n",
       "\u001b[0;34m    array([1., 0., 0.])\u001b[0m\n",
       "\u001b[0;34m    >>> y_true = [0, 0, 0, 0, 0, 0]\u001b[0m\n",
       "\u001b[0;34m    >>> recall_score(y_true, y_pred, average=None)\u001b[0m\n",
       "\u001b[0;34m    array([0.5, 0. , 0. ])\u001b[0m\n",
       "\u001b[0;34m    >>> recall_score(y_true, y_pred, average=None, zero_division=1)\u001b[0m\n",
       "\u001b[0;34m    array([0.5, 1. , 1. ])\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Notes\u001b[0m\n",
       "\u001b[0;34m    -----\u001b[0m\n",
       "\u001b[0;34m    When ``true positive + false negative == 0``, recall returns 0 and raises\u001b[0m\n",
       "\u001b[0;34m    ``UndefinedMetricWarning``. This behavior can be modified with\u001b[0m\n",
       "\u001b[0;34m    ``zero_division``.\u001b[0m\n",
       "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision_recall_fscore_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                                 \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                                 \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                                 \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                                 \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'recall'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                                 \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                                 \u001b[0mzero_division\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mzero_division\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      ~/Documents/venv/tlfMaths3.6/lib/python3.6/site-packages/sklearn/metrics/_classification.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "recall_score??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mzero_division\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'warn'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "\u001b[0;34m@\u001b[0m\u001b[0m_deprecate_positional_args\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;32mdef\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0mzero_division\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"warn\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Compute the precision\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    The precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001b[0m\n",
       "\u001b[0;34m    true positives and ``fp`` the number of false positives. The precision is\u001b[0m\n",
       "\u001b[0;34m    intuitively the ability of the classifier not to label as positive a sample\u001b[0m\n",
       "\u001b[0;34m    that is negative.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    The best value is 1 and the worst value is 0.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Read more in the :ref:`User Guide <precision_recall_f_measure_metrics>`.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Parameters\u001b[0m\n",
       "\u001b[0;34m    ----------\u001b[0m\n",
       "\u001b[0;34m    y_true : 1d array-like, or label indicator array / sparse matrix\u001b[0m\n",
       "\u001b[0;34m        Ground truth (correct) target values.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    y_pred : 1d array-like, or label indicator array / sparse matrix\u001b[0m\n",
       "\u001b[0;34m        Estimated targets as returned by a classifier.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    labels : list, optional\u001b[0m\n",
       "\u001b[0;34m        The set of labels to include when ``average != 'binary'``, and their\u001b[0m\n",
       "\u001b[0;34m        order if ``average is None``. Labels present in the data can be\u001b[0m\n",
       "\u001b[0;34m        excluded, for example to calculate a multiclass average ignoring a\u001b[0m\n",
       "\u001b[0;34m        majority negative class, while labels not present in the data will\u001b[0m\n",
       "\u001b[0;34m        result in 0 components in a macro average. For multilabel targets,\u001b[0m\n",
       "\u001b[0;34m        labels are column indices. By default, all labels in ``y_true`` and\u001b[0m\n",
       "\u001b[0;34m        ``y_pred`` are used in sorted order.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        .. versionchanged:: 0.17\u001b[0m\n",
       "\u001b[0;34m           parameter *labels* improved for multiclass problem.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    pos_label : str or int, 1 by default\u001b[0m\n",
       "\u001b[0;34m        The class to report if ``average='binary'`` and the data is binary.\u001b[0m\n",
       "\u001b[0;34m        If the data are multiclass or multilabel, this will be ignored;\u001b[0m\n",
       "\u001b[0;34m        setting ``labels=[pos_label]`` and ``average != 'binary'`` will report\u001b[0m\n",
       "\u001b[0;34m        scores for that label only.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    average : string, [None, 'binary' (default), 'micro', 'macro', 'samples', \\\u001b[0m\n",
       "\u001b[0;34m                       'weighted']\u001b[0m\n",
       "\u001b[0;34m        This parameter is required for multiclass/multilabel targets.\u001b[0m\n",
       "\u001b[0;34m        If ``None``, the scores for each class are returned. Otherwise, this\u001b[0m\n",
       "\u001b[0;34m        determines the type of averaging performed on the data:\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        ``'binary'``:\u001b[0m\n",
       "\u001b[0;34m            Only report results for the class specified by ``pos_label``.\u001b[0m\n",
       "\u001b[0;34m            This is applicable only if targets (``y_{true,pred}``) are binary.\u001b[0m\n",
       "\u001b[0;34m        ``'micro'``:\u001b[0m\n",
       "\u001b[0;34m            Calculate metrics globally by counting the total true positives,\u001b[0m\n",
       "\u001b[0;34m            false negatives and false positives.\u001b[0m\n",
       "\u001b[0;34m        ``'macro'``:\u001b[0m\n",
       "\u001b[0;34m            Calculate metrics for each label, and find their unweighted\u001b[0m\n",
       "\u001b[0;34m            mean.  This does not take label imbalance into account.\u001b[0m\n",
       "\u001b[0;34m        ``'weighted'``:\u001b[0m\n",
       "\u001b[0;34m            Calculate metrics for each label, and find their average weighted\u001b[0m\n",
       "\u001b[0;34m            by support (the number of true instances for each label). This\u001b[0m\n",
       "\u001b[0;34m            alters 'macro' to account for label imbalance; it can result in an\u001b[0m\n",
       "\u001b[0;34m            F-score that is not between precision and recall.\u001b[0m\n",
       "\u001b[0;34m        ``'samples'``:\u001b[0m\n",
       "\u001b[0;34m            Calculate metrics for each instance, and find their average (only\u001b[0m\n",
       "\u001b[0;34m            meaningful for multilabel classification where this differs from\u001b[0m\n",
       "\u001b[0;34m            :func:`accuracy_score`).\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    sample_weight : array-like of shape (n_samples,), default=None\u001b[0m\n",
       "\u001b[0;34m        Sample weights.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    zero_division : \"warn\", 0 or 1, default=\"warn\"\u001b[0m\n",
       "\u001b[0;34m        Sets the value to return when there is a zero division. If set to\u001b[0m\n",
       "\u001b[0;34m        \"warn\", this acts as 0, but warnings are also raised.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Returns\u001b[0m\n",
       "\u001b[0;34m    -------\u001b[0m\n",
       "\u001b[0;34m    precision : float (if average is not None) or array of float, shape =\\\u001b[0m\n",
       "\u001b[0;34m        [n_unique_labels]\u001b[0m\n",
       "\u001b[0;34m        Precision of the positive class in binary classification or weighted\u001b[0m\n",
       "\u001b[0;34m        average of the precision of each class for the multiclass task.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    See also\u001b[0m\n",
       "\u001b[0;34m    --------\u001b[0m\n",
       "\u001b[0;34m    precision_recall_fscore_support, multilabel_confusion_matrix\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Examples\u001b[0m\n",
       "\u001b[0;34m    --------\u001b[0m\n",
       "\u001b[0;34m    >>> from sklearn.metrics import precision_score\u001b[0m\n",
       "\u001b[0;34m    >>> y_true = [0, 1, 2, 0, 1, 2]\u001b[0m\n",
       "\u001b[0;34m    >>> y_pred = [0, 2, 1, 0, 0, 1]\u001b[0m\n",
       "\u001b[0;34m    >>> precision_score(y_true, y_pred, average='macro')\u001b[0m\n",
       "\u001b[0;34m    0.22...\u001b[0m\n",
       "\u001b[0;34m    >>> precision_score(y_true, y_pred, average='micro')\u001b[0m\n",
       "\u001b[0;34m    0.33...\u001b[0m\n",
       "\u001b[0;34m    >>> precision_score(y_true, y_pred, average='weighted')\u001b[0m\n",
       "\u001b[0;34m    0.22...\u001b[0m\n",
       "\u001b[0;34m    >>> precision_score(y_true, y_pred, average=None)\u001b[0m\n",
       "\u001b[0;34m    array([0.66..., 0.        , 0.        ])\u001b[0m\n",
       "\u001b[0;34m    >>> y_pred = [0, 0, 0, 0, 0, 0]\u001b[0m\n",
       "\u001b[0;34m    >>> precision_score(y_true, y_pred, average=None)\u001b[0m\n",
       "\u001b[0;34m    array([0.33..., 0.        , 0.        ])\u001b[0m\n",
       "\u001b[0;34m    >>> precision_score(y_true, y_pred, average=None, zero_division=1)\u001b[0m\n",
       "\u001b[0;34m    array([0.33..., 1.        , 1.        ])\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Notes\u001b[0m\n",
       "\u001b[0;34m    -----\u001b[0m\n",
       "\u001b[0;34m    When ``true positive + false positive == 0``, precision returns 0 and\u001b[0m\n",
       "\u001b[0;34m    raises ``UndefinedMetricWarning``. This behavior can be\u001b[0m\n",
       "\u001b[0;34m    modified with ``zero_division``.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision_recall_fscore_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                                 \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                                 \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                                 \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                                 \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'precision'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                                 \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                                 \u001b[0mzero_division\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mzero_division\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      ~/Documents/venv/tlfMaths3.6/lib/python3.6/site-packages/sklearn/metrics/_classification.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "precision_score??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mprecision_recall_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mprobas_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "\u001b[0;34m@\u001b[0m\u001b[0m_deprecate_positional_args\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;32mdef\u001b[0m \u001b[0mprecision_recall_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobas_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                           \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Compute precision-recall pairs for different probability thresholds\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Note: this implementation is restricted to the binary classification task.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    The precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001b[0m\n",
       "\u001b[0;34m    true positives and ``fp`` the number of false positives. The precision is\u001b[0m\n",
       "\u001b[0;34m    intuitively the ability of the classifier not to label as positive a sample\u001b[0m\n",
       "\u001b[0;34m    that is negative.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    The recall is the ratio ``tp / (tp + fn)`` where ``tp`` is the number of\u001b[0m\n",
       "\u001b[0;34m    true positives and ``fn`` the number of false negatives. The recall is\u001b[0m\n",
       "\u001b[0;34m    intuitively the ability of the classifier to find all the positive samples.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    The last precision and recall values are 1. and 0. respectively and do not\u001b[0m\n",
       "\u001b[0;34m    have a corresponding threshold.  This ensures that the graph starts on the\u001b[0m\n",
       "\u001b[0;34m    y axis.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Read more in the :ref:`User Guide <precision_recall_f_measure_metrics>`.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Parameters\u001b[0m\n",
       "\u001b[0;34m    ----------\u001b[0m\n",
       "\u001b[0;34m    y_true : array, shape = [n_samples]\u001b[0m\n",
       "\u001b[0;34m        True binary labels. If labels are not either {-1, 1} or {0, 1}, then\u001b[0m\n",
       "\u001b[0;34m        pos_label should be explicitly given.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    probas_pred : array, shape = [n_samples]\u001b[0m\n",
       "\u001b[0;34m        Estimated probabilities or decision function.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    pos_label : int or str, default=None\u001b[0m\n",
       "\u001b[0;34m        The label of the positive class.\u001b[0m\n",
       "\u001b[0;34m        When ``pos_label=None``, if y_true is in {-1, 1} or {0, 1},\u001b[0m\n",
       "\u001b[0;34m        ``pos_label`` is set to 1, otherwise an error will be raised.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    sample_weight : array-like of shape (n_samples,), default=None\u001b[0m\n",
       "\u001b[0;34m        Sample weights.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Returns\u001b[0m\n",
       "\u001b[0;34m    -------\u001b[0m\n",
       "\u001b[0;34m    precision : array, shape = [n_thresholds + 1]\u001b[0m\n",
       "\u001b[0;34m        Precision values such that element i is the precision of\u001b[0m\n",
       "\u001b[0;34m        predictions with score >= thresholds[i] and the last element is 1.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    recall : array, shape = [n_thresholds + 1]\u001b[0m\n",
       "\u001b[0;34m        Decreasing recall values such that element i is the recall of\u001b[0m\n",
       "\u001b[0;34m        predictions with score >= thresholds[i] and the last element is 0.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    thresholds : array, shape = [n_thresholds <= len(np.unique(probas_pred))]\u001b[0m\n",
       "\u001b[0;34m        Increasing thresholds on the decision function used to compute\u001b[0m\n",
       "\u001b[0;34m        precision and recall.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    See also\u001b[0m\n",
       "\u001b[0;34m    --------\u001b[0m\n",
       "\u001b[0;34m    average_precision_score : Compute average precision from prediction scores\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    roc_curve : Compute Receiver operating characteristic (ROC) curve\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Examples\u001b[0m\n",
       "\u001b[0;34m    --------\u001b[0m\n",
       "\u001b[0;34m    >>> import numpy as np\u001b[0m\n",
       "\u001b[0;34m    >>> from sklearn.metrics import precision_recall_curve\u001b[0m\n",
       "\u001b[0;34m    >>> y_true = np.array([0, 0, 1, 1])\u001b[0m\n",
       "\u001b[0;34m    >>> y_scores = np.array([0.1, 0.4, 0.35, 0.8])\u001b[0m\n",
       "\u001b[0;34m    >>> precision, recall, thresholds = precision_recall_curve(\u001b[0m\n",
       "\u001b[0;34m    ...     y_true, y_scores)\u001b[0m\n",
       "\u001b[0;34m    >>> precision\u001b[0m\n",
       "\u001b[0;34m    array([0.66666667, 0.5       , 1.        , 1.        ])\u001b[0m\n",
       "\u001b[0;34m    >>> recall\u001b[0m\n",
       "\u001b[0;34m    array([1. , 0.5, 0.5, 0. ])\u001b[0m\n",
       "\u001b[0;34m    >>> thresholds\u001b[0m\n",
       "\u001b[0;34m    array([0.35, 0.4 , 0.8 ])\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresholds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_binary_clf_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobas_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                             \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mprecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtps\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtps\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mprecision\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprecision\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mrecall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtps\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;31m# stop when full recall attained\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;31m# and reverse the outputs so recall is decreasing\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlast_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearchsorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprecision\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msl\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrecall\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msl\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresholds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msl\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      ~/Documents/venv/tlfMaths3.6/lib/python3.6/site-packages/sklearn/metrics/_ranking.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "precision_recall_curve??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mprecision_recall_fscore_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'precision'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'recall'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'f-score'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mzero_division\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'warn'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "\u001b[0;34m@\u001b[0m\u001b[0m_deprecate_positional_args\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;32mdef\u001b[0m \u001b[0mprecision_recall_fscore_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                    \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                    \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'precision'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'recall'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                              \u001b[0;34m'f-score'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                    \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                    \u001b[0mzero_division\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"warn\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Compute precision, recall, F-measure and support for each class\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    The precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001b[0m\n",
       "\u001b[0;34m    true positives and ``fp`` the number of false positives. The precision is\u001b[0m\n",
       "\u001b[0;34m    intuitively the ability of the classifier not to label as positive a sample\u001b[0m\n",
       "\u001b[0;34m    that is negative.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    The recall is the ratio ``tp / (tp + fn)`` where ``tp`` is the number of\u001b[0m\n",
       "\u001b[0;34m    true positives and ``fn`` the number of false negatives. The recall is\u001b[0m\n",
       "\u001b[0;34m    intuitively the ability of the classifier to find all the positive samples.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    The F-beta score can be interpreted as a weighted harmonic mean of\u001b[0m\n",
       "\u001b[0;34m    the precision and recall, where an F-beta score reaches its best\u001b[0m\n",
       "\u001b[0;34m    value at 1 and worst score at 0.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    The F-beta score weights recall more than precision by a factor of\u001b[0m\n",
       "\u001b[0;34m    ``beta``. ``beta == 1.0`` means recall and precision are equally important.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    The support is the number of occurrences of each class in ``y_true``.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    If ``pos_label is None`` and in binary classification, this function\u001b[0m\n",
       "\u001b[0;34m    returns the average precision, recall and F-measure if ``average``\u001b[0m\n",
       "\u001b[0;34m    is one of ``'micro'``, ``'macro'``, ``'weighted'`` or ``'samples'``.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Read more in the :ref:`User Guide <precision_recall_f_measure_metrics>`.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Parameters\u001b[0m\n",
       "\u001b[0;34m    ----------\u001b[0m\n",
       "\u001b[0;34m    y_true : 1d array-like, or label indicator array / sparse matrix\u001b[0m\n",
       "\u001b[0;34m        Ground truth (correct) target values.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    y_pred : 1d array-like, or label indicator array / sparse matrix\u001b[0m\n",
       "\u001b[0;34m        Estimated targets as returned by a classifier.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    beta : float, 1.0 by default\u001b[0m\n",
       "\u001b[0;34m        The strength of recall versus precision in the F-score.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    labels : list, optional\u001b[0m\n",
       "\u001b[0;34m        The set of labels to include when ``average != 'binary'``, and their\u001b[0m\n",
       "\u001b[0;34m        order if ``average is None``. Labels present in the data can be\u001b[0m\n",
       "\u001b[0;34m        excluded, for example to calculate a multiclass average ignoring a\u001b[0m\n",
       "\u001b[0;34m        majority negative class, while labels not present in the data will\u001b[0m\n",
       "\u001b[0;34m        result in 0 components in a macro average. For multilabel targets,\u001b[0m\n",
       "\u001b[0;34m        labels are column indices. By default, all labels in ``y_true`` and\u001b[0m\n",
       "\u001b[0;34m        ``y_pred`` are used in sorted order.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    pos_label : str or int, 1 by default\u001b[0m\n",
       "\u001b[0;34m        The class to report if ``average='binary'`` and the data is binary.\u001b[0m\n",
       "\u001b[0;34m        If the data are multiclass or multilabel, this will be ignored;\u001b[0m\n",
       "\u001b[0;34m        setting ``labels=[pos_label]`` and ``average != 'binary'`` will report\u001b[0m\n",
       "\u001b[0;34m        scores for that label only.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    average : string, [None (default), 'binary', 'micro', 'macro', 'samples', \\\u001b[0m\n",
       "\u001b[0;34m                       'weighted']\u001b[0m\n",
       "\u001b[0;34m        If ``None``, the scores for each class are returned. Otherwise, this\u001b[0m\n",
       "\u001b[0;34m        determines the type of averaging performed on the data:\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        ``'binary'``:\u001b[0m\n",
       "\u001b[0;34m            Only report results for the class specified by ``pos_label``.\u001b[0m\n",
       "\u001b[0;34m            This is applicable only if targets (``y_{true,pred}``) are binary.\u001b[0m\n",
       "\u001b[0;34m        ``'micro'``:\u001b[0m\n",
       "\u001b[0;34m            Calculate metrics globally by counting the total true positives,\u001b[0m\n",
       "\u001b[0;34m            false negatives and false positives.\u001b[0m\n",
       "\u001b[0;34m        ``'macro'``:\u001b[0m\n",
       "\u001b[0;34m            Calculate metrics for each label, and find their unweighted\u001b[0m\n",
       "\u001b[0;34m            mean.  This does not take label imbalance into account.\u001b[0m\n",
       "\u001b[0;34m        ``'weighted'``:\u001b[0m\n",
       "\u001b[0;34m            Calculate metrics for each label, and find their average weighted\u001b[0m\n",
       "\u001b[0;34m            by support (the number of true instances for each label). This\u001b[0m\n",
       "\u001b[0;34m            alters 'macro' to account for label imbalance; it can result in an\u001b[0m\n",
       "\u001b[0;34m            F-score that is not between precision and recall.\u001b[0m\n",
       "\u001b[0;34m        ``'samples'``:\u001b[0m\n",
       "\u001b[0;34m            Calculate metrics for each instance, and find their average (only\u001b[0m\n",
       "\u001b[0;34m            meaningful for multilabel classification where this differs from\u001b[0m\n",
       "\u001b[0;34m            :func:`accuracy_score`).\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    warn_for : tuple or set, for internal use\u001b[0m\n",
       "\u001b[0;34m        This determines which warnings will be made in the case that this\u001b[0m\n",
       "\u001b[0;34m        function is being used to return only one of its metrics.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    sample_weight : array-like of shape (n_samples,), default=None\u001b[0m\n",
       "\u001b[0;34m        Sample weights.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    zero_division : \"warn\", 0 or 1, default=\"warn\"\u001b[0m\n",
       "\u001b[0;34m        Sets the value to return when there is a zero division:\u001b[0m\n",
       "\u001b[0;34m           - recall: when there are no positive labels\u001b[0m\n",
       "\u001b[0;34m           - precision: when there are no positive predictions\u001b[0m\n",
       "\u001b[0;34m           - f-score: both\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        If set to \"warn\", this acts as 0, but warnings are also raised.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Returns\u001b[0m\n",
       "\u001b[0;34m    -------\u001b[0m\n",
       "\u001b[0;34m    precision : float (if average is not None) or array of float, shape =\\\u001b[0m\n",
       "\u001b[0;34m        [n_unique_labels]\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    recall : float (if average is not None) or array of float, , shape =\\\u001b[0m\n",
       "\u001b[0;34m        [n_unique_labels]\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    fbeta_score : float (if average is not None) or array of float, shape =\\\u001b[0m\n",
       "\u001b[0;34m        [n_unique_labels]\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    support : None (if average is not None) or array of int, shape =\\\u001b[0m\n",
       "\u001b[0;34m        [n_unique_labels]\u001b[0m\n",
       "\u001b[0;34m        The number of occurrences of each label in ``y_true``.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    References\u001b[0m\n",
       "\u001b[0;34m    ----------\u001b[0m\n",
       "\u001b[0;34m    .. [1] `Wikipedia entry for the Precision and recall\u001b[0m\n",
       "\u001b[0;34m           <https://en.wikipedia.org/wiki/Precision_and_recall>`_\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    .. [2] `Wikipedia entry for the F1-score\u001b[0m\n",
       "\u001b[0;34m           <https://en.wikipedia.org/wiki/F1_score>`_\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    .. [3] `Discriminative Methods for Multi-labeled Classification Advances\u001b[0m\n",
       "\u001b[0;34m           in Knowledge Discovery and Data Mining (2004), pp. 22-30 by Shantanu\u001b[0m\n",
       "\u001b[0;34m           Godbole, Sunita Sarawagi\u001b[0m\n",
       "\u001b[0;34m           <http://www.godbole.net/shantanu/pubs/multilabelsvm-pakdd04.pdf>`_\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Examples\u001b[0m\n",
       "\u001b[0;34m    --------\u001b[0m\n",
       "\u001b[0;34m    >>> import numpy as np\u001b[0m\n",
       "\u001b[0;34m    >>> from sklearn.metrics import precision_recall_fscore_support\u001b[0m\n",
       "\u001b[0;34m    >>> y_true = np.array(['cat', 'dog', 'pig', 'cat', 'dog', 'pig'])\u001b[0m\n",
       "\u001b[0;34m    >>> y_pred = np.array(['cat', 'pig', 'dog', 'cat', 'cat', 'dog'])\u001b[0m\n",
       "\u001b[0;34m    >>> precision_recall_fscore_support(y_true, y_pred, average='macro')\u001b[0m\n",
       "\u001b[0;34m    (0.22..., 0.33..., 0.26..., None)\u001b[0m\n",
       "\u001b[0;34m    >>> precision_recall_fscore_support(y_true, y_pred, average='micro')\u001b[0m\n",
       "\u001b[0;34m    (0.33..., 0.33..., 0.33..., None)\u001b[0m\n",
       "\u001b[0;34m    >>> precision_recall_fscore_support(y_true, y_pred, average='weighted')\u001b[0m\n",
       "\u001b[0;34m    (0.22..., 0.33..., 0.26..., None)\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    It is possible to compute per-label precisions, recalls, F1-scores and\u001b[0m\n",
       "\u001b[0;34m    supports instead of averaging:\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    >>> precision_recall_fscore_support(y_true, y_pred, average=None,\u001b[0m\n",
       "\u001b[0;34m    ... labels=['pig', 'dog', 'cat'])\u001b[0m\n",
       "\u001b[0;34m    (array([0.        , 0.        , 0.66...]),\u001b[0m\n",
       "\u001b[0;34m     array([0., 0., 1.]), array([0. , 0. , 0.8]),\u001b[0m\n",
       "\u001b[0;34m     array([2, 2, 2]))\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Notes\u001b[0m\n",
       "\u001b[0;34m    -----\u001b[0m\n",
       "\u001b[0;34m    When ``true positive + false positive == 0``, precision is undefined;\u001b[0m\n",
       "\u001b[0;34m    When ``true positive + false negative == 0``, recall is undefined.\u001b[0m\n",
       "\u001b[0;34m    In such cases, by default the metric will be set to 0, as will f-score,\u001b[0m\n",
       "\u001b[0;34m    and ``UndefinedMetricWarning`` will be raised. This behavior can be\u001b[0m\n",
       "\u001b[0;34m    modified with ``zero_division``.\u001b[0m\n",
       "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0m_check_zero_division\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzero_division\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_set_wise_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                    \u001b[0mpos_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msamplewise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maverage\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'samples'\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mMCM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmultilabel_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                      \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                      \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamplewise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msamplewise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtp_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMCM\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpred_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtp_sum\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mMCM\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtrue_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtp_sum\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mMCM\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0maverage\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'micro'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mtp_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtp_sum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mpred_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpred_sum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mtrue_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrue_sum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;31m# Finally, we have all our sufficient statistics. Divide! #\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbeta2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;31m# Divide, and on zero-division, set scores and/or warn according to\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;31m# zero_division:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mprecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_prf_divide\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtp_sum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_sum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'precision'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                            \u001b[0;34m'predicted'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn_for\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzero_division\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mrecall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_prf_divide\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtp_sum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_sum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'recall'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                         \u001b[0;34m'true'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn_for\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzero_division\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;31m# warn for f-score only if zero_division is warn, it is in warn_for\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;31m# and BOTH prec and rec are ill-defined\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mzero_division\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"warn\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"f-score\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mwarn_for\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpred_sum\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrue_sum\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0m_warn_prf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"true nor predicted\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'F-score is'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_sum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;31m# if tp == 0 F will be 1 only if all predictions are zero, all labels are\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;31m# zero, and zero_division=1. In all other case, 0\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misposinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mf_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecall\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbeta2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mprecision\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrecall\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mdenom\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdenom\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m  \u001b[0;31m# avoid division by 0\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mf_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mprecision\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mrecall\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;31m# Average the results\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0maverage\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'weighted'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrue_sum\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mzero_division_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mzero_division\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"warn\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# precision is zero_division if there are no positive predictions\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# recall is zero_division if there are no positive labels\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# fscore is zero_division if all labels AND predictions are\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# negative\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mzero_division_value\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpred_sum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0mzero_division_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0mzero_division_value\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpred_sum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32melif\u001b[0m \u001b[0maverage\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'samples'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0maverage\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32massert\u001b[0m \u001b[0maverage\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'binary'\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprecision\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mprecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mrecall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mf_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mtrue_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# return no support\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_sum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      ~/Documents/venv/tlfMaths3.6/lib/python3.6/site-packages/sklearn/metrics/_classification.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "precision_recall_fscore_support??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8370879772350012"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_train_5, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6511713705958311"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_train_5, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[53892,   687],\n",
       "       [ 1891,  3530]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train_5, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8370879772350012, 0.6511713705958311)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3530/(3530 + 687), 3530/(3530 + 1891) # Precision and recall score if I consider TRUE as correct classification of 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9661007833927899, 0.987412741164184)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "53892/(53892 + 1891), 53892/(53892 + 687) # Precision and recall score if I consider TRUE as correct classification of non-5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now your 5-detector does not look as shiny as it did when you looked at its accuracy. When it claims an image represents a 5, it is correct only 83.7% of the time. Moreover, it only detects 65.1% of the 5s.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is often convenient to **combine precision and recall** into a single metric called the **`F1 score`**, in particular if you need a simple way to compare two classifiers. The F1 score is the harmonic mean of precision and recall (Equation 3-3). Whereas the regular mean treats all values equally, the harmonic mean gives much more weight to low values. As a result, the classifier will only get a high F1 score if both recall and precision are high.\n",
    "\n",
    "**Equation 3-3. $F_1$** </br>\n",
    "$$F_1 = \\frac{TP}{TP + \\frac{FN + FP}{2}}$$\n",
    "\n",
    "To compute the F1 score, simply call the `f1_score()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mzero_division\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'warn'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "\u001b[0;34m@\u001b[0m\u001b[0m_deprecate_positional_args\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;32mdef\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzero_division\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"warn\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Compute the F1 score, also known as balanced F-score or F-measure\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    The F1 score can be interpreted as a weighted average of the precision and\u001b[0m\n",
       "\u001b[0;34m    recall, where an F1 score reaches its best value at 1 and worst score at 0.\u001b[0m\n",
       "\u001b[0;34m    The relative contribution of precision and recall to the F1 score are\u001b[0m\n",
       "\u001b[0;34m    equal. The formula for the F1 score is::\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        F1 = 2 * (precision * recall) / (precision + recall)\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    In the multi-class and multi-label case, this is the average of\u001b[0m\n",
       "\u001b[0;34m    the F1 score of each class with weighting depending on the ``average``\u001b[0m\n",
       "\u001b[0;34m    parameter.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Read more in the :ref:`User Guide <precision_recall_f_measure_metrics>`.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Parameters\u001b[0m\n",
       "\u001b[0;34m    ----------\u001b[0m\n",
       "\u001b[0;34m    y_true : 1d array-like, or label indicator array / sparse matrix\u001b[0m\n",
       "\u001b[0;34m        Ground truth (correct) target values.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    y_pred : 1d array-like, or label indicator array / sparse matrix\u001b[0m\n",
       "\u001b[0;34m        Estimated targets as returned by a classifier.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    labels : list, optional\u001b[0m\n",
       "\u001b[0;34m        The set of labels to include when ``average != 'binary'``, and their\u001b[0m\n",
       "\u001b[0;34m        order if ``average is None``. Labels present in the data can be\u001b[0m\n",
       "\u001b[0;34m        excluded, for example to calculate a multiclass average ignoring a\u001b[0m\n",
       "\u001b[0;34m        majority negative class, while labels not present in the data will\u001b[0m\n",
       "\u001b[0;34m        result in 0 components in a macro average. For multilabel targets,\u001b[0m\n",
       "\u001b[0;34m        labels are column indices. By default, all labels in ``y_true`` and\u001b[0m\n",
       "\u001b[0;34m        ``y_pred`` are used in sorted order.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        .. versionchanged:: 0.17\u001b[0m\n",
       "\u001b[0;34m           parameter *labels* improved for multiclass problem.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    pos_label : str or int, 1 by default\u001b[0m\n",
       "\u001b[0;34m        The class to report if ``average='binary'`` and the data is binary.\u001b[0m\n",
       "\u001b[0;34m        If the data are multiclass or multilabel, this will be ignored;\u001b[0m\n",
       "\u001b[0;34m        setting ``labels=[pos_label]`` and ``average != 'binary'`` will report\u001b[0m\n",
       "\u001b[0;34m        scores for that label only.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    average : string, [None, 'binary' (default), 'micro', 'macro', 'samples', \\\u001b[0m\n",
       "\u001b[0;34m                       'weighted']\u001b[0m\n",
       "\u001b[0;34m        This parameter is required for multiclass/multilabel targets.\u001b[0m\n",
       "\u001b[0;34m        If ``None``, the scores for each class are returned. Otherwise, this\u001b[0m\n",
       "\u001b[0;34m        determines the type of averaging performed on the data:\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        ``'binary'``:\u001b[0m\n",
       "\u001b[0;34m            Only report results for the class specified by ``pos_label``.\u001b[0m\n",
       "\u001b[0;34m            This is applicable only if targets (``y_{true,pred}``) are binary.\u001b[0m\n",
       "\u001b[0;34m        ``'micro'``:\u001b[0m\n",
       "\u001b[0;34m            Calculate metrics globally by counting the total true positives,\u001b[0m\n",
       "\u001b[0;34m            false negatives and false positives.\u001b[0m\n",
       "\u001b[0;34m        ``'macro'``:\u001b[0m\n",
       "\u001b[0;34m            Calculate metrics for each label, and find their unweighted\u001b[0m\n",
       "\u001b[0;34m            mean.  This does not take label imbalance into account.\u001b[0m\n",
       "\u001b[0;34m        ``'weighted'``:\u001b[0m\n",
       "\u001b[0;34m            Calculate metrics for each label, and find their average weighted\u001b[0m\n",
       "\u001b[0;34m            by support (the number of true instances for each label). This\u001b[0m\n",
       "\u001b[0;34m            alters 'macro' to account for label imbalance; it can result in an\u001b[0m\n",
       "\u001b[0;34m            F-score that is not between precision and recall.\u001b[0m\n",
       "\u001b[0;34m        ``'samples'``:\u001b[0m\n",
       "\u001b[0;34m            Calculate metrics for each instance, and find their average (only\u001b[0m\n",
       "\u001b[0;34m            meaningful for multilabel classification where this differs from\u001b[0m\n",
       "\u001b[0;34m            :func:`accuracy_score`).\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    sample_weight : array-like of shape (n_samples,), default=None\u001b[0m\n",
       "\u001b[0;34m        Sample weights.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    zero_division : \"warn\", 0 or 1, default=\"warn\"\u001b[0m\n",
       "\u001b[0;34m        Sets the value to return when there is a zero division, i.e. when all\u001b[0m\n",
       "\u001b[0;34m        predictions and labels are negative. If set to \"warn\", this acts as 0,\u001b[0m\n",
       "\u001b[0;34m        but warnings are also raised.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Returns\u001b[0m\n",
       "\u001b[0;34m    -------\u001b[0m\n",
       "\u001b[0;34m    f1_score : float or array of float, shape = [n_unique_labels]\u001b[0m\n",
       "\u001b[0;34m        F1 score of the positive class in binary classification or weighted\u001b[0m\n",
       "\u001b[0;34m        average of the F1 scores of each class for the multiclass task.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    See also\u001b[0m\n",
       "\u001b[0;34m    --------\u001b[0m\n",
       "\u001b[0;34m    fbeta_score, precision_recall_fscore_support, jaccard_score,\u001b[0m\n",
       "\u001b[0;34m    multilabel_confusion_matrix\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    References\u001b[0m\n",
       "\u001b[0;34m    ----------\u001b[0m\n",
       "\u001b[0;34m    .. [1] `Wikipedia entry for the F1-score\u001b[0m\n",
       "\u001b[0;34m           <https://en.wikipedia.org/wiki/F1_score>`_\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Examples\u001b[0m\n",
       "\u001b[0;34m    --------\u001b[0m\n",
       "\u001b[0;34m    >>> from sklearn.metrics import f1_score\u001b[0m\n",
       "\u001b[0;34m    >>> y_true = [0, 1, 2, 0, 1, 2]\u001b[0m\n",
       "\u001b[0;34m    >>> y_pred = [0, 2, 1, 0, 0, 1]\u001b[0m\n",
       "\u001b[0;34m    >>> f1_score(y_true, y_pred, average='macro')\u001b[0m\n",
       "\u001b[0;34m    0.26...\u001b[0m\n",
       "\u001b[0;34m    >>> f1_score(y_true, y_pred, average='micro')\u001b[0m\n",
       "\u001b[0;34m    0.33...\u001b[0m\n",
       "\u001b[0;34m    >>> f1_score(y_true, y_pred, average='weighted')\u001b[0m\n",
       "\u001b[0;34m    0.26...\u001b[0m\n",
       "\u001b[0;34m    >>> f1_score(y_true, y_pred, average=None)\u001b[0m\n",
       "\u001b[0;34m    array([0.8, 0. , 0. ])\u001b[0m\n",
       "\u001b[0;34m    >>> y_true = [0, 0, 0, 0, 0, 0]\u001b[0m\n",
       "\u001b[0;34m    >>> y_pred = [0, 0, 0, 0, 0, 0]\u001b[0m\n",
       "\u001b[0;34m    >>> f1_score(y_true, y_pred, zero_division=1)\u001b[0m\n",
       "\u001b[0;34m    1.0...\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Notes\u001b[0m\n",
       "\u001b[0;34m    -----\u001b[0m\n",
       "\u001b[0;34m    When ``true positive + false positive == 0``, precision is undefined;\u001b[0m\n",
       "\u001b[0;34m    When ``true positive + false negative == 0``, recall is undefined.\u001b[0m\n",
       "\u001b[0;34m    In such cases, by default the metric will be set to 0, as will f-score,\u001b[0m\n",
       "\u001b[0;34m    and ``UndefinedMetricWarning`` will be raised. This behavior can be\u001b[0m\n",
       "\u001b[0;34m    modified with ``zero_division``.\u001b[0m\n",
       "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mfbeta_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                       \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                       \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                       \u001b[0mzero_division\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mzero_division\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      ~/Documents/venv/tlfMaths3.6/lib/python3.6/site-packages/sklearn/metrics/_classification.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f1_score??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7325171197343846"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_train_5, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, (60000,))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train_5), y_train_5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_train_5, y_train_perfect_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The `F1 score` favors classifiers that have similar `precision and recall`. </br>\n",
    "* `This is not always what you want`: in some contexts you mostly `care about precision`, and `in other contexts you really care about recall`. </br>\n",
    "* `For example`, \n",
    "    * if you trained a classifier to detect videos that are safe for kids, you would probably prefer a classifier that rejects many good videos (low recall) but keeps only safe ones (high precision), rather than a classifier that has a much higher recall but lets a few really bad videos show up in your product (in such cases, you may even want to add a human pipeline to check the classifier’s video selection). \n",
    "    * On the other hand, suppose you train a classifier to detect shoplifters in surveillance images: it is probably fine if your classifier has only 30% precision as long as it has 99% recall (sure, the security guards will get a few false alerts, but almost all shoplifters will get caught).\n",
    "    \n",
    "`Unfortunately, you can’t have it both ways`: `increasing precision reduces recall, and vice versa`. This is called the `precision/recall trade-off`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision/Recall Trade-off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand this trade-off, let’s look at how the `SGDClassifier` makes its classification decisions. </br>\n",
    "For each instance, it computes a score based on a decision function. If that score is greater than a threshold, it assigns the instance to the positive class; otherwise it assigns it to the negative class. <br>\n",
    "Figure 3-3 shows a few digits positioned from the lowest score on the left to the highest score on the right. Suppose the decision threshold is positioned at the central arrow (between the two 5s): you will find 4 true positives (actual 5s) on the right of that threshold, and 1 false positive (actually a 6). Therefore, with that threshold, the precision is 80% (4 out of 5). But out of 6 actual 5s, the classifier only detects 4, so the recall is 67% (4 out of 6). If you raise the threshold (move it to the arrow on the right), the false positive (the 6) becomes a true negative, thereby increasing the precision (up to 100% in this case), but one true positive becomes a false negative, decreasing recall down to 50%. Conversely, lowering the threshold increases recall and reduces precision.\n",
    "\n",
    "![Precision/Recall Trade-Off](images/precision_recall_trade_off.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Scikit-Learn does not let you set the threshold directly**, but it does give you access to the decision scores that it uses to make predictions. Instead of calling the classifier’s `predict()` method, you can call its `decision_function()` method, which returns a score for each instance, and then use any threshold you want to make predictions based on those scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score = sgd_clf.decision_function([some_digit])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2164.22030239])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_some_digit_pred = y_score > threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_some_digit_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `SGDClassifier` uses a threshold equal to 0, so the previous code returns the same result as the `predict()` method (i.e., True). Let’s raise the threshold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = 8000\n",
    "y_some_digit_pred = y_score > threshold\n",
    "y_some_digit_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This confirms that raising the threshold decreases recall**. The image actually represents a 5, and the classifier detects it when the threshold is 0, but it misses it when the threshold is increased to 8,000."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do you decide which threshold to use? First, use the `cross_val_predict()` function to get the scores of all instances in the training set, but this time specify that you want to return decision scores instead of predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scores = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3, method='decision_function')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1200.930512369027"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_scores[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-146348.56726173862,\n",
       " 49441.437659047755,\n",
       " -18071.705387563583,\n",
       " 14096.88570506998)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_scores.min(), y_scores.max(), y_scores.mean(), y_scores.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these scores, use the `precision_recall_curve()` function to compute precision and recall for all possible thresholds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "precisions, recalls, thresholds = precision_recall_curve(y_train_5, y_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, numpy.ndarray, numpy.ndarray)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(precisions), type(recalls), type(thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((59967,), (59967,), (59966,))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precisions.shape, recalls.shape, thresholds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8213166144200627, 0.6766279284264896, -530.5237933325346)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind = 55500\n",
    "precisions[ind], recalls[ind], thresholds[ind]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, use `Matplotlib` to plot `precision` and `recall` as functions of the threshold value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.plot(thresholds, precisions[:-1], 'b--', label='Precision')\n",
    "    plt.plot(thresholds, recalls[:-1], 'g-', label='Recall')\n",
    "    plt.legend()\n",
    "    plt.xlabel('Threshold')\n",
    "    plt.title('Precision and recall versus the decision threshold')\n",
    "    plt.vlines(thresholds[57000], min(precisions.min(), recalls.min()), precisions[57000], colors='r', linestyles='dotted')\n",
    "    plt.hlines(precisions[57000], thresholds.min(), thresholds[57000], colors='r', linestyles='dotted')\n",
    "    plt.hlines(recalls[57000], thresholds.min(), thresholds[57000], colors='r', linestyles='dotted')\n",
    "    plt.grid()\n",
    "    \n",
    "plot_precision_recall_vs_threshold(precisions, recalls, thresholds)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOTE\n",
    "\n",
    "> You may wonder why the `precision curve is bumpier than the recall curve` in above Figure. <br>\n",
    "> The reason is that precision may sometimes go down when you raise the threshold (although in general it will go up). To understand why, look back at Figure 3-3 and notice what happens when you start from the central threshold and move it just one digit to the right: precision goes from 4/5 (80%) down to 3/4 (75%). On the other hand, recall can only go down when the threshold is increased, which explains why its curve looks smooth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to `select a good precision/recall trade-off` is to plot precision directly against recall, as shown in below Figure (the same threshold as earlier is highlighted)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_precision_vs_recall(precisions, recalls):\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.plot(recalls, precisions)\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precisions')\n",
    "    plt.title('Precision versus Recall')\n",
    "    plt.vlines(recalls[57000], precisions.min(), precisions[57000], colors='r', linestyles='dotted')\n",
    "    plt.hlines(precisions[57000], recalls.min(), recalls[57000], colors='r', linestyles='dotted')\n",
    "    plt.grid()\n",
    "    \n",
    "plot_precision_vs_recall(precisions, recalls)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You can see that precision really starts to fall sharply around 75% recall. You will probably want to select a precision/recall trade-off just before that drop—for example, at around 60% recall. But of course, the choice depends on your project.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you decide to aim for 90% precision. You look up the first plot and find that you need to use a threshold of about 3,500. To be more precise you can search for the lowest threshold that gives you at least 90% precision (`np.argmax()` will give you the first index of the maximum value, which in this case means the `first True value`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_90_precision = thresholds[np.argmax(precisions >= 0.9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3370.0194991439557"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold_90_precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make predictions (on the training set for now), `instead of calling the classifier’s predict()` method, you can run this code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_90 = (y_scores >= threshold_90_precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check these `predictions' precision and recall`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9000345901072293"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_train_5, y_train_pred_90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4799852425751706"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_train_5, y_train_pred_90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, you have a `90% precision classifier`! As you can see, it is fairly easy to create a classifier with virtually any precision you want: just set a high enough threshold, and you’re done. <br>\n",
    "But wait, not so fast. A high-precision classifier is not very useful if its recall is too low!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TIP\n",
    "\n",
    "> If someone says, \"**`Let's reach 99% precision,\" you should ask, \"At what recall?`**\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The ROC Curve\n",
    "\n",
    "* The `receiver operating characteristic (ROC) curve` is another common tool used with binary classifiers. \n",
    "* It is very similar to the precision/recall curve, but instead of plotting precision versus recall, the ROC curve plots the `true positive rate (another name for recall)` against the `false positive rate (FPR)`. The FPR is the ratio of negative instances that are incorrectly classified as positive. It is equal to 1 - (minus) the `true negative rate (TNR)`, which is the ratio of negative instances that are correctly classified as negative. The TNR is also called `specificity`. Hence, **the ROC curve plots `sensitivity (recall)` versus 1 - (minus) specificity**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To plot the ROC curve, you first use the `roc_curve()` function to compute the `TPR and FPR` for various threshold values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdrop_intermediate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "\u001b[0;34m@\u001b[0m\u001b[0m_deprecate_positional_args\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;32mdef\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m              \u001b[0mdrop_intermediate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Compute Receiver operating characteristic (ROC)\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Note: this implementation is restricted to the binary classification task.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Read more in the :ref:`User Guide <roc_metrics>`.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Parameters\u001b[0m\n",
       "\u001b[0;34m    ----------\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    y_true : array, shape = [n_samples]\u001b[0m\n",
       "\u001b[0;34m        True binary labels. If labels are not either {-1, 1} or {0, 1}, then\u001b[0m\n",
       "\u001b[0;34m        pos_label should be explicitly given.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    y_score : array, shape = [n_samples]\u001b[0m\n",
       "\u001b[0;34m        Target scores, can either be probability estimates of the positive\u001b[0m\n",
       "\u001b[0;34m        class, confidence values, or non-thresholded measure of decisions\u001b[0m\n",
       "\u001b[0;34m        (as returned by \"decision_function\" on some classifiers).\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    pos_label : int or str, default=None\u001b[0m\n",
       "\u001b[0;34m        The label of the positive class.\u001b[0m\n",
       "\u001b[0;34m        When ``pos_label=None``, if y_true is in {-1, 1} or {0, 1},\u001b[0m\n",
       "\u001b[0;34m        ``pos_label`` is set to 1, otherwise an error will be raised.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    sample_weight : array-like of shape (n_samples,), default=None\u001b[0m\n",
       "\u001b[0;34m        Sample weights.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    drop_intermediate : boolean, optional (default=True)\u001b[0m\n",
       "\u001b[0;34m        Whether to drop some suboptimal thresholds which would not appear\u001b[0m\n",
       "\u001b[0;34m        on a plotted ROC curve. This is useful in order to create lighter\u001b[0m\n",
       "\u001b[0;34m        ROC curves.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        .. versionadded:: 0.17\u001b[0m\n",
       "\u001b[0;34m           parameter *drop_intermediate*.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Returns\u001b[0m\n",
       "\u001b[0;34m    -------\u001b[0m\n",
       "\u001b[0;34m    fpr : array, shape = [>2]\u001b[0m\n",
       "\u001b[0;34m        Increasing false positive rates such that element i is the false\u001b[0m\n",
       "\u001b[0;34m        positive rate of predictions with score >= thresholds[i].\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    tpr : array, shape = [>2]\u001b[0m\n",
       "\u001b[0;34m        Increasing true positive rates such that element i is the true\u001b[0m\n",
       "\u001b[0;34m        positive rate of predictions with score >= thresholds[i].\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    thresholds : array, shape = [n_thresholds]\u001b[0m\n",
       "\u001b[0;34m        Decreasing thresholds on the decision function used to compute\u001b[0m\n",
       "\u001b[0;34m        fpr and tpr. `thresholds[0]` represents no instances being predicted\u001b[0m\n",
       "\u001b[0;34m        and is arbitrarily set to `max(y_score) + 1`.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    See also\u001b[0m\n",
       "\u001b[0;34m    --------\u001b[0m\n",
       "\u001b[0;34m    roc_auc_score : Compute the area under the ROC curve\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Notes\u001b[0m\n",
       "\u001b[0;34m    -----\u001b[0m\n",
       "\u001b[0;34m    Since the thresholds are sorted from low to high values, they\u001b[0m\n",
       "\u001b[0;34m    are reversed upon returning them to ensure they correspond to both ``fpr``\u001b[0m\n",
       "\u001b[0;34m    and ``tpr``, which are sorted in reversed order during their calculation.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    References\u001b[0m\n",
       "\u001b[0;34m    ----------\u001b[0m\n",
       "\u001b[0;34m    .. [1] `Wikipedia entry for the Receiver operating characteristic\u001b[0m\n",
       "\u001b[0;34m            <https://en.wikipedia.org/wiki/Receiver_operating_characteristic>`_\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    .. [2] Fawcett T. An introduction to ROC analysis[J]. Pattern Recognition\u001b[0m\n",
       "\u001b[0;34m           Letters, 2006, 27(8):861-874.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Examples\u001b[0m\n",
       "\u001b[0;34m    --------\u001b[0m\n",
       "\u001b[0;34m    >>> import numpy as np\u001b[0m\n",
       "\u001b[0;34m    >>> from sklearn import metrics\u001b[0m\n",
       "\u001b[0;34m    >>> y = np.array([1, 1, 2, 2])\u001b[0m\n",
       "\u001b[0;34m    >>> scores = np.array([0.1, 0.4, 0.35, 0.8])\u001b[0m\n",
       "\u001b[0;34m    >>> fpr, tpr, thresholds = metrics.roc_curve(y, scores, pos_label=2)\u001b[0m\n",
       "\u001b[0;34m    >>> fpr\u001b[0m\n",
       "\u001b[0;34m    array([0. , 0. , 0.5, 0.5, 1. ])\u001b[0m\n",
       "\u001b[0;34m    >>> tpr\u001b[0m\n",
       "\u001b[0;34m    array([0. , 0.5, 0.5, 1. , 1. ])\u001b[0m\n",
       "\u001b[0;34m    >>> thresholds\u001b[0m\n",
       "\u001b[0;34m    array([1.8 , 0.8 , 0.4 , 0.35, 0.1 ])\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresholds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_binary_clf_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;31m# Attempt to drop thresholds corresponding to points in between and\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;31m# collinear with other points. These are always suboptimal and do not\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;31m# appear on a plotted ROC curve (and thus do not affect the AUC).\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;31m# Here np.diff(_, 2) is used as a \"second derivative\" to tell if there\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;31m# is a corner at the point. Both fps and tps must be tested to handle\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;31m# thresholds with multiple data points (which are combined in\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;31m# _binary_clf_curve). This keeps all cases where the point should be kept,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;31m# but does not drop more complicated cases like fps = [1, 3, 7],\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;31m# tps = [1, 2, 4]; there is no harm in keeping too many thresholds.\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mdrop_intermediate\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfps\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0moptimal_idxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                      \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_or\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                                    \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                      \u001b[0;32mTrue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mfps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moptimal_idxs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mtps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moptimal_idxs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mthresholds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthresholds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moptimal_idxs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;31m# Add an extra threshold position\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;31m# to make sure that the curve starts at (0, 0)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtps\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfps\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mthresholds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mthresholds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresholds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mfps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No negative samples in y_true, \"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                      \u001b[0;34m\"false positive value should be meaningless\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                      \u001b[0mUndefinedMetricWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mfpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mfpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfps\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mtps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No positive samples in y_true, \"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                      \u001b[0;34m\"true positive value should be meaningless\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                      \u001b[0mUndefinedMetricWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mtpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mtpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtps\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresholds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      ~/Documents/venv/tlfMaths3.6/lib/python3.6/site-packages/sklearn/metrics/_ranking.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "roc_curve??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_train_5, y_scores)\n",
    "# fpr, tpr, thresholds = roc_curve(y_train_5, y_scores, drop_intermediate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, numpy.ndarray, numpy.ndarray)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(fpr), type(tpr), type(thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3908,), (3908,), (3908,))"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr.shape, tpr.shape, thresholds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.003444548269480936, 0.3879358052019923, 5344.335016926949)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind = 340\n",
    "fpr[ind], tpr[ind], thresholds[ind]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then you can plot the FPR against the TPR using Matplotlib. This code produces the plot in below Figure (plot):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_roc_curve(fpr, tpr, label=None):\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.plot(fpr, tpr, linewidth=2, label=label)\n",
    "    plt.plot([0, 1], [0, 1], 'k--', label='Purely Random Classifier') # Dashed diagonal\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate (Recall)')\n",
    "    plt.title('This ROC curve plots the false positive rate against the true positive rate for all possible thresholds')\n",
    "\n",
    "plot_roc_curve(fpr, tpr, label='SGD Classifier')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In above Figure/Plot: <br>\n",
    "Once again there is a trade-off: `the higher the recall (TPR), the more false positives (FPR)` the classifier produces. The dotted line represents the ROC curve of a purely random classifier; a good classifier stays as far away from that line as possible (toward the top-left corner)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `One way to compare classifiers is to measure the area under the curve (AUC)`. \n",
    "* A perfect classifier will have a `ROC AUC` equal to 1, whereas a purely random classifier will have a `ROC AUC` equal to 0.5. <br>\n",
    "\n",
    "Scikit-Learn provides a function to compute the `ROC AUC`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'macro'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmax_fpr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmulti_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'raise'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "\u001b[0;34m@\u001b[0m\u001b[0m_deprecate_positional_args\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;32mdef\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"macro\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                  \u001b[0mmax_fpr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"raise\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Compute Area Under the Receiver Operating Characteristic Curve (ROC AUC)\u001b[0m\n",
       "\u001b[0;34m    from prediction scores.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Note: this implementation can be used with binary, multiclass and\u001b[0m\n",
       "\u001b[0;34m    multilabel classification, but some restrictions apply (see Parameters).\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Read more in the :ref:`User Guide <roc_metrics>`.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Parameters\u001b[0m\n",
       "\u001b[0;34m    ----------\u001b[0m\n",
       "\u001b[0;34m    y_true : array-like of shape (n_samples,) or (n_samples, n_classes)\u001b[0m\n",
       "\u001b[0;34m        True labels or binary label indicators. The binary and multiclass cases\u001b[0m\n",
       "\u001b[0;34m        expect labels with shape (n_samples,) while the multilabel case expects\u001b[0m\n",
       "\u001b[0;34m        binary label indicators with shape (n_samples, n_classes).\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    y_score : array-like of shape (n_samples,) or (n_samples, n_classes)\u001b[0m\n",
       "\u001b[0;34m        Target scores. In the binary and multilabel cases, these can be either\u001b[0m\n",
       "\u001b[0;34m        probability estimates or non-thresholded decision values (as returned\u001b[0m\n",
       "\u001b[0;34m        by `decision_function` on some classifiers). In the multiclass case,\u001b[0m\n",
       "\u001b[0;34m        these must be probability estimates which sum to 1. The binary\u001b[0m\n",
       "\u001b[0;34m        case expects a shape (n_samples,), and the scores must be the scores of\u001b[0m\n",
       "\u001b[0;34m        the class with the greater label. The multiclass and multilabel\u001b[0m\n",
       "\u001b[0;34m        cases expect a shape (n_samples, n_classes). In the multiclass case,\u001b[0m\n",
       "\u001b[0;34m        the order of the class scores must correspond to the order of\u001b[0m\n",
       "\u001b[0;34m        ``labels``, if provided, or else to the numerical or lexicographical\u001b[0m\n",
       "\u001b[0;34m        order of the labels in ``y_true``.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    average : {'micro', 'macro', 'samples', 'weighted'} or None, \\\u001b[0m\n",
       "\u001b[0;34m            default='macro'\u001b[0m\n",
       "\u001b[0;34m        If ``None``, the scores for each class are returned. Otherwise,\u001b[0m\n",
       "\u001b[0;34m        this determines the type of averaging performed on the data:\u001b[0m\n",
       "\u001b[0;34m        Note: multiclass ROC AUC currently only handles the 'macro' and\u001b[0m\n",
       "\u001b[0;34m        'weighted' averages.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        ``'micro'``:\u001b[0m\n",
       "\u001b[0;34m            Calculate metrics globally by considering each element of the label\u001b[0m\n",
       "\u001b[0;34m            indicator matrix as a label.\u001b[0m\n",
       "\u001b[0;34m        ``'macro'``:\u001b[0m\n",
       "\u001b[0;34m            Calculate metrics for each label, and find their unweighted\u001b[0m\n",
       "\u001b[0;34m            mean.  This does not take label imbalance into account.\u001b[0m\n",
       "\u001b[0;34m        ``'weighted'``:\u001b[0m\n",
       "\u001b[0;34m            Calculate metrics for each label, and find their average, weighted\u001b[0m\n",
       "\u001b[0;34m            by support (the number of true instances for each label).\u001b[0m\n",
       "\u001b[0;34m        ``'samples'``:\u001b[0m\n",
       "\u001b[0;34m            Calculate metrics for each instance, and find their average.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Will be ignored when ``y_true`` is binary.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    sample_weight : array-like of shape (n_samples,), default=None\u001b[0m\n",
       "\u001b[0;34m        Sample weights.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    max_fpr : float > 0 and <= 1, default=None\u001b[0m\n",
       "\u001b[0;34m        If not ``None``, the standardized partial AUC [2]_ over the range\u001b[0m\n",
       "\u001b[0;34m        [0, max_fpr] is returned. For the multiclass case, ``max_fpr``,\u001b[0m\n",
       "\u001b[0;34m        should be either equal to ``None`` or ``1.0`` as AUC ROC partial\u001b[0m\n",
       "\u001b[0;34m        computation currently is not supported for multiclass.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    multi_class : {'raise', 'ovr', 'ovo'}, default='raise'\u001b[0m\n",
       "\u001b[0;34m        Multiclass only. Determines the type of configuration to use. The\u001b[0m\n",
       "\u001b[0;34m        default value raises an error, so either ``'ovr'`` or ``'ovo'`` must be\u001b[0m\n",
       "\u001b[0;34m        passed explicitly.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        ``'ovr'``:\u001b[0m\n",
       "\u001b[0;34m            Computes the AUC of each class against the rest [3]_ [4]_. This\u001b[0m\n",
       "\u001b[0;34m            treats the multiclass case in the same way as the multilabel case.\u001b[0m\n",
       "\u001b[0;34m            Sensitive to class imbalance even when ``average == 'macro'``,\u001b[0m\n",
       "\u001b[0;34m            because class imbalance affects the composition of each of the\u001b[0m\n",
       "\u001b[0;34m            'rest' groupings.\u001b[0m\n",
       "\u001b[0;34m        ``'ovo'``:\u001b[0m\n",
       "\u001b[0;34m            Computes the average AUC of all possible pairwise combinations of\u001b[0m\n",
       "\u001b[0;34m            classes [5]_. Insensitive to class imbalance when\u001b[0m\n",
       "\u001b[0;34m            ``average == 'macro'``.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    labels : array-like of shape (n_classes,), default=None\u001b[0m\n",
       "\u001b[0;34m        Multiclass only. List of labels that index the classes in ``y_score``.\u001b[0m\n",
       "\u001b[0;34m        If ``None``, the numerical or lexicographical order of the labels in\u001b[0m\n",
       "\u001b[0;34m        ``y_true`` is used.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Returns\u001b[0m\n",
       "\u001b[0;34m    -------\u001b[0m\n",
       "\u001b[0;34m    auc : float\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    References\u001b[0m\n",
       "\u001b[0;34m    ----------\u001b[0m\n",
       "\u001b[0;34m    .. [1] `Wikipedia entry for the Receiver operating characteristic\u001b[0m\n",
       "\u001b[0;34m            <https://en.wikipedia.org/wiki/Receiver_operating_characteristic>`_\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    .. [2] `Analyzing a portion of the ROC curve. McClish, 1989\u001b[0m\n",
       "\u001b[0;34m            <https://www.ncbi.nlm.nih.gov/pubmed/2668680>`_\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    .. [3] Provost, F., Domingos, P. (2000). Well-trained PETs: Improving\u001b[0m\n",
       "\u001b[0;34m           probability estimation trees (Section 6.2), CeDER Working Paper\u001b[0m\n",
       "\u001b[0;34m           #IS-00-04, Stern School of Business, New York University.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    .. [4] `Fawcett, T. (2006). An introduction to ROC analysis. Pattern\u001b[0m\n",
       "\u001b[0;34m            Recognition Letters, 27(8), 861-874.\u001b[0m\n",
       "\u001b[0;34m            <https://www.sciencedirect.com/science/article/pii/S016786550500303X>`_\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    .. [5] `Hand, D.J., Till, R.J. (2001). A Simple Generalisation of the Area\u001b[0m\n",
       "\u001b[0;34m            Under the ROC Curve for Multiple Class Classification Problems.\u001b[0m\n",
       "\u001b[0;34m            Machine Learning, 45(2), 171-186.\u001b[0m\n",
       "\u001b[0;34m            <http://link.springer.com/article/10.1023/A:1010920819831>`_\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    See also\u001b[0m\n",
       "\u001b[0;34m    --------\u001b[0m\n",
       "\u001b[0;34m    average_precision_score : Area under the precision-recall curve\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    roc_curve : Compute Receiver operating characteristic (ROC) curve\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Examples\u001b[0m\n",
       "\u001b[0;34m    --------\u001b[0m\n",
       "\u001b[0;34m    >>> import numpy as np\u001b[0m\n",
       "\u001b[0;34m    >>> from sklearn.metrics import roc_auc_score\u001b[0m\n",
       "\u001b[0;34m    >>> y_true = np.array([0, 0, 1, 1])\u001b[0m\n",
       "\u001b[0;34m    >>> y_scores = np.array([0.1, 0.4, 0.35, 0.8])\u001b[0m\n",
       "\u001b[0;34m    >>> roc_auc_score(y_true, y_scores)\u001b[0m\n",
       "\u001b[0;34m    0.75\u001b[0m\n",
       "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0my_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0my_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                  \u001b[0my_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                  \u001b[0my_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# do not support partial ROC computation for multiclass\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mmax_fpr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmax_fpr\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Partial AUC computation not available in \"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                             \u001b[0;34m\"multiclass setting, 'max_fpr' must be\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                             \u001b[0;34m\" set to `None`, received `max_fpr={0}` \"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                             \u001b[0;34m\"instead\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_fpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mmulti_class\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'raise'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"multi_class must be in ('ovo', 'ovr')\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0m_multiclass_roc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                         \u001b[0mmulti_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32melif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_binarize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0m_average_binary_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_binary_roc_auc_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                             \u001b[0mmax_fpr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_fpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                     \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                     \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# multilabel-indicator\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0m_average_binary_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_binary_roc_auc_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                             \u001b[0mmax_fpr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_fpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                     \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                     \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      ~/Documents/venv/tlfMaths3.6/lib/python3.6/site-packages/sklearn/metrics/_ranking.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "roc_auc_score??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9604938554008616"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_train_5, y_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **`TIP`**\n",
    "\n",
    "> Since the ROC curve is so similar to the precision/recall (PR) curve, you may wonder **`how to decide which one to use`**. <br>\n",
    "> As a rule of thumb, you should **`prefer the PR curve`** whenever the positive class is rare or when you care more about the false positives than the false negatives. Otherwise, **`use the ROC curve`**. <br>\n",
    "> **For example, looking at the previous ROC curve (and the ROC AUC score), you may think that the classifier is really good. But this is mostly because there are few positives (5s) compared to the negatives (non-5s). In contrast, the PR curve makes it clear that the classifier has room for improvement (the curve could be closer to the top-left corner).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Let’s now train a `RandomForestClassifier` and compare its ROC curve and ROC AUC score to those of the SGDClassifier.** \n",
    "- First, you need to get scores for each instance in the training set. But due to the way it works (see Chapter 7), `the RandomForestClassifier class does not have a decision_function() method`. Instead, it has a **`predict_proba()`** method. <br>\n",
    "- Scikit-Learn classifiers generally have one or the other, or both. The `predict_proba()` method returns an array containing a row per instance and a column per class, each containing the probability that the given instance belongs to the given class (e.g., 70% chance that the image represents a 5):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_clf = RandomForestClassifier(random_state=42)\n",
    "y_probas_forest = cross_val_predict(forest_clf, X_train, y_train_5, cv=3, method='predict_proba')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `roc_curve()` function expects labels and scores, but instead of scores you can give it class probabilities. Let’s use the positive class’s probability as the score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
